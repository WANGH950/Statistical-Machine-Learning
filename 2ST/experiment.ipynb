{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计机器学习第二次作业\n",
    "### 葡萄酒品种分类——基于Pytorch\n",
    "王恒 计算数学 220220934161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26205511df0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "import time\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "data =  datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = torch.tensor(data.data)\n",
    "data_labels = torch.tensor(data.target)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([178, 13])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([178, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = torch.cat([data_features,data_labels],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = data_set.shape[0]\n",
    "alpha = 0.7\n",
    "train_len = int(length*alpha)\n",
    "test_len = length - train_len\n",
    "train_data, test_data = torch.utils.data.random_split(data_set,[train_len,test_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_data = torch.tensor([item.numpy() for item in train_data])\n",
    "test_data = torch.tensor([item.numpy() for item in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([124, 14])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([54, 14])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class NaiveBayes(nn.Module):\n",
    "    def __init__(self, n, full_labels, S, lamb) -> None:\n",
    "        super(NaiveBayes,self).__init__()\n",
    "        # 归一化参数\n",
    "        self.max = None\n",
    "        self.min = None\n",
    "        self.n = n # 特征数量\n",
    "        self.full_labels = full_labels # 所有标签\n",
    "        self.K = len(full_labels) # 标签数量\n",
    "        self.lamb = lamb # 贝叶斯估计参数lambda\n",
    "        self.S = S # 每个特征分划区间数，这里默认都为S\n",
    "        self.cond_prob = torch.zeros([self.K,self.n,S]) # 条件概率\n",
    "        self.pre_prob = torch.zeros([self.K]) # 先验概率\n",
    "\n",
    "    def forward(self, features):\n",
    "        B,n = features.shape\n",
    "        assert n == self.n\n",
    "        post_prob = torch.ones([B,1])*self.pre_prob\n",
    "        # 归一化\n",
    "        features = (features - self.min) / (self.max - self.min) * 2 - 1\n",
    "        delta_x = 2 / (self.S - 2)\n",
    "        for i in range(B):\n",
    "            for j in range(self.K):\n",
    "                for k in range(n):\n",
    "                    if features[i,k] < -1: post_prob[i,j] *= self.cond_prob[j,k,0]\n",
    "                    elif features[i,k] >= 1: post_prob[i,j] *= self.cond_prob[j,k,-1]\n",
    "                    else:\n",
    "                        for h in range(self.S-2):\n",
    "                            l = -1 + h * delta_x\n",
    "                            r = l + delta_x\n",
    "                            if features[i,k] >= l and features[i,k] < r:\n",
    "                                post_prob[i,j] *= self.cond_prob[j,k,h+1]\n",
    "                                break\n",
    "        return self.full_labels[torch.argmax(post_prob,dim=1)]\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        # 计算先验概率\n",
    "        N,_ = train_data.shape\n",
    "        self.max = torch.max(train_data[:,:-1],dim=0).values\n",
    "        self.min = torch.min(train_data[:,:-1],dim=0).values\n",
    "        train_data[:,:-1] = (train_data[:,:-1] - self.min) / (self.max - self.min) * 2 - 1\n",
    "        features = train_data[:,:-1] # 特征\n",
    "        labels = train_data[:,-1:].int() # 标签\n",
    "        delta_x = 2 / (self.S - 2)\n",
    "        for i in range(self.K):\n",
    "            labels_i = labels == self.full_labels[i]\n",
    "            self.pre_prob[i] = (labels_i.sum() + self.lamb) / (N + self.K*self.lamb)\n",
    "            for j in range(self.n):\n",
    "                self.cond_prob[i,j,0] = 1 / self.S\n",
    "                for k in range(self.S-1):\n",
    "                    l = -1 + k * delta_x\n",
    "                    r = l + delta_x\n",
    "                    features_ij = features[labels_i[:,0],j]\n",
    "                    features_ijk = features_ij[(features_ij>=l)*(features_ij<r)]\n",
    "                    self.cond_prob[i,j,k+1] = (features_ijk.shape[0] + self.lamb) / (labels_i.sum() + self.S*self.lamb)\n",
    "        return self.pre_prob, self.cond_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayse = NaiveBayes(\n",
    "    n=train_data.shape[1]-1,\n",
    "    full_labels=torch.tensor([0,1,2]),\n",
    "    S=10,\n",
    "    lamb=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "_,_ = naive_bayse.fit(\n",
    "    train_data = copy.deepcopy(train_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "predicts = naive_bayse(\n",
    "    copy.deepcopy(test_data[:,:-1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 2, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 2, 2, 2, 0, 1, 2, 2, 1, 1, 0,\n",
       "        1, 2, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "        0, 0, 2, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 0,\n",
       "        1, 2, 0, 1, 0, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:,-1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9444)\n"
     ]
    }
   ],
   "source": [
    "# 打印准确率\n",
    "print(torch.sum(predicts == test_data[:,-1].int()) / test_data.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义模型（ID3算法）\n",
    "# class Node():\n",
    "#     def __init__(self, father = None, childrens = [], mark = None) -> None:\n",
    "#         super(Node,self).__init__()\n",
    "#         self.father = father\n",
    "#         self.childrens = childrens\n",
    "#         self.mark = mark\n",
    "#         self.split = []\n",
    "    \n",
    "#     def is_leaf(self):\n",
    "#         if self.mark is None:\n",
    "#             return False\n",
    "#         else:\n",
    "#             return True\n",
    "\n",
    "# class DecisionTree(nn.Module):\n",
    "#     def __init__(self, full_features, full_labels, S, esplison = 0.001) -> None:\n",
    "#         super(DecisionTree,self).__init__()\n",
    "#         self.esplison = esplison\n",
    "#         self.S = S # 特征划分数\n",
    "#         self.full_features = full_features\n",
    "#         self.feature_num = len(full_features)\n",
    "#         self.full_labels = full_labels\n",
    "#         self.K = len(full_labels)\n",
    "#         # 归一化参数\n",
    "#         self.min = None\n",
    "#         self.max = None\n",
    "#         self.Tree = Node()\n",
    "\n",
    "#     def create_tree(self,D,A,node = None,root = None):\n",
    "#         if node is None: \n",
    "#             node = self.Tree\n",
    "#             root = self.Tree\n",
    "#             # 归一化\n",
    "#             self.max = torch.max(D[:,:-1],dim=0).values\n",
    "#             self.min = torch.min(D[:,:-1],dim=0).values\n",
    "#             D[:,:-1] = (D[:,:-1] - self.min) / (self.max - self.min) * 2 - 1\n",
    "#         features = D[:,:-1]\n",
    "#         labels = D[:,-1:]\n",
    "#         # 只有一种标签时候直接返回\n",
    "#         if torch.unique(labels).shape[0] == 1:\n",
    "#             node.mark = D[0,-1]\n",
    "#             return root\n",
    "#         # 标签数量为空时直接返回\n",
    "#         elif len(A) == 0:\n",
    "#             count = torch.bincount(labels)\n",
    "#             mark = torch.argmax(count)\n",
    "#             node.mark = mark\n",
    "#             return root\n",
    "#         else:\n",
    "#             # 计算各特征的信息增益，选择最大信息增益特征\n",
    "#             g = self.information_gain(D,A[0])\n",
    "#             Ag = 0\n",
    "#             for i in range(len(A) - 1):\n",
    "#                 gi = self.information_gain(D,A[i+1])\n",
    "#                 if gi > g:\n",
    "#                     g = gi\n",
    "#                     Ag = i+1\n",
    "#             # 达到精度返回\n",
    "#             if g < self.esplison:\n",
    "#                 count = torch.bincount(labels)\n",
    "#                 mark = torch.argmax(count)\n",
    "#                 node.mark = mark\n",
    "#                 return root\n",
    "#             # 未达到精度继续递归生成子节点\n",
    "#             else:\n",
    "#                 l = None\n",
    "#                 r = -1\n",
    "#                 delta_x = 2 / (self.S - 2)\n",
    "#                 feature_i = features[:,Ag]\n",
    "#                 Ai = copy.deepcopy(A)\n",
    "#                 Ai[Ag] = False\n",
    "#                 for i in range(self.S):\n",
    "#                     if i == self.S - 1: r = None\n",
    "#                     if l is None:\n",
    "#                         index = feature_i < r\n",
    "#                         # 当前数据不空\n",
    "#                         if index.sum() > 0:\n",
    "#                             node.split.append(lambda x: x < r) # 用于判别并分划当前特征\n",
    "#                             Di = D[index,:] # Di一定非空\n",
    "#                             assert Di.shape[0] > 0\n",
    "#                             nodei = Node(father=node)\n",
    "#                             # 递归处理子节点\n",
    "#                             self.create_tree(Di,Ai,nodei,root)\n",
    "#                             node.childrens.append(nodei)\n",
    "#                             l = r\n",
    "#                             r = r + delta_x\n",
    "#                     elif r is None:\n",
    "#                         index = feature_i >= l\n",
    "#                         # 当前数据不空\n",
    "#                         if index.sum() > 0:\n",
    "#                             node.split.append(lambda x: x < r) # 用于判别并分划当前特征\n",
    "#                             Di = D[index,:] # Di一定非空\n",
    "#                             assert Di.shape[0] > 0\n",
    "#                             nodei = Node(father=node)\n",
    "#                             # 递归处理子节点\n",
    "#                             self.create_tree(Di,Ai,nodei,root)\n",
    "#                             node.childrens.append(nodei)\n",
    "#                             l = r\n",
    "#                             r = r + delta_x\n",
    "                        \n",
    "                            \n",
    "                \n",
    "\n",
    "#     # 计算经验熵\n",
    "#     def empirical_entropy(self,D):\n",
    "#         labels = data_set[:,-1:]\n",
    "#         HD = 0\n",
    "#         for j in range(self.K):\n",
    "#             labels_j = labels == self.full_labels[j]\n",
    "#             HD -= labels_j.sum() / D * torch.log2(labels_j.sum() / D)\n",
    "#         return HD\n",
    "\n",
    "#     # 计算A对于数据集D的经验条件熵\n",
    "#     def empirical_cond_entropy(self,D,A):\n",
    "#         D_ = D.shape[0]\n",
    "#         index = self.full_features == A\n",
    "#         features = D[:,:-1]\n",
    "#         labels = D[:,-1:]\n",
    "#         DA = features[:,index]\n",
    "#         DAi = DA[DA < -1,None]\n",
    "#         Li = labels[DA < -1,:]\n",
    "#         HDA = len(DAi) / D_ * self.empirical_entropy(torch.cat([DAi,Li],dim=1))\n",
    "#         DAi = DA[DA >= 1,None]\n",
    "#         Li = labels[DA >= 1,:]\n",
    "#         HDA += len(DAi) / D_ * self.empirical_entropy(torch.cat([DAi,Li],dim=1))\n",
    "#         delta_x = 2 / (self.S - 2)\n",
    "#         for i in range(self.S - 2):\n",
    "#             l = -1 + i * delta_x\n",
    "#             r = l + delta_x\n",
    "#             index_i = (DA >= l) * (DA < r)\n",
    "#             DAi = DA[index_i,None]\n",
    "#             Li = labels[index_i,:]\n",
    "#             HDA += len(DAi) / D_ * self.empirical_entropy(torch.cat([DAi,Li],dim=1))\n",
    "#         return HDA\n",
    "\n",
    "#     # 计算信息增益\n",
    "#     def information_gain(self,data_set,feature):\n",
    "#         if self.min is None or self.max is None:\n",
    "#             self.max = torch.max(train_data[:,:-1],dim=0).values\n",
    "#             self.min = torch.min(train_data[:,:-1],dim=0).values\n",
    "#         # 特征归一化到[-1,1]\n",
    "#         train_data[:,:-1] = (train_data[:,:-1] - self.min) / (self.max - self.min) * 2 - 1\n",
    "\n",
    "#         index = self.full_features == feature\n",
    "#         D,_ = data_set\n",
    "#         assert torch.sum(index) == 1 and D > 1\n",
    "#         # 计算经验熵\n",
    "#         HD = self.empirical_entropy(data_set)\n",
    "#         # 计算feature对于数据集data_set的经验条件熵\n",
    "#         HDA = self.empirical_cond_entropy(data_set,feature)\n",
    "#         return HD - HDA\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic 回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic(nn.Module):\n",
    "    def __init__(self,feature_num,class_num) -> None:\n",
    "        super(Logistic,self).__init__()\n",
    "        self.feature_num = feature_num\n",
    "        self.class_num = class_num\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.BatchNorm1d(feature_num),\n",
    "            nn.Linear(feature_num,class_num-1,bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,d = x.shape\n",
    "        assert d == self.feature_num and B > 0\n",
    "        y = torch.cat([torch.exp(self.linear(x)),torch.ones([B,1])],dim=1)\n",
    "        y = y / torch.sum(y,dim=1,keepdim=True)\n",
    "        return y\n",
    "    \n",
    "# 负对数似然损失函数\n",
    "class NLLLoss(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self,y_pre,y_rel):\n",
    "        assert y_pre.shape == y_rel.shape\n",
    "        loss = -torch.log(y_pre)*y_rel\n",
    "        return torch.sum(loss)\n",
    "\n",
    "def train(model, data_set, batch_size, epoch = 1000, learning_rate = 1e-3):\n",
    "    N,_ = data_set.shape\n",
    "    criterion = NLLLoss()\n",
    "    optim = torch.optim.SGD(model.parameters(),learning_rate,momentum=0) # 动量设置为0\n",
    "    \n",
    "    start = time.time()\n",
    "    loss_values = torch.zeros(epoch)\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        index = torch.randint(0,N,[batch_size]) # 随机选取batch条数据\n",
    "        data_i = data_set[index,:]\n",
    "        x_i = data_i[:,:-1].to(torch.float32)\n",
    "        y_i = nn.functional.one_hot(data_i[:,-1].to(torch.int64),num_classes=model.class_num)\n",
    "        outputs = model(x_i)\n",
    "        loss = criterion(outputs,y_i)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        model.eval()\n",
    "        loss_values[i] = loss.item()\n",
    "\n",
    "        print('\\r%5d/{}|{}{}|{:.2f}s  [Loss: %e]'.format(\n",
    "            epoch,\n",
    "            \"#\"*int((i+1)/epoch*50),\n",
    "            \" \"*(50-int((i+1)/epoch*50)),\n",
    "            time.time() - start) %\n",
    "            (i+1,\n",
    "            loss_values[i]), end = ' ', flush=True)\n",
    "    print(\"\\nTraining has been completed.\")\n",
    "    return loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Logistic(\n",
    "    feature_num=train_data.shape[1]-1,\n",
    "    class_num=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|8.81s  [Loss: 3.584634e-01]                        \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "loss_values = train(\n",
    "    model=model,\n",
    "    data_set=train_data,\n",
    "    batch_size=20,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model(\n",
    "    test_data[:,:-1].float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = torch.argmax(predicts,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 2, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 2, 1, 0,\n",
       "        1, 2, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "        0, 0, 2, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 0,\n",
       "        1, 2, 0, 1, 0, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:,-1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9444)\n"
     ]
    }
   ],
   "source": [
    "# 打印准确率\n",
    "print(torch.sum(predicts == test_data[:,-1].int()) / test_data.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 支持向量机"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class SVMLinear(nn.Module):\n",
    "    def __init__(self,feature_num) -> None:\n",
    "        super(SVMLinear,self).__init__()\n",
    "        self.feature_num = feature_num\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_num) # 特征批量归一化，学习归一化参数\n",
    "        self.linear = nn.Linear(feature_num,1)\n",
    "    \n",
    "    def forward(self, x, signed = True):\n",
    "        B,d = x.shape\n",
    "        assert B > 0 and d == self.feature_num\n",
    "        normed = self.batch_norm(x)\n",
    "        outputs = self.linear(normed)\n",
    "        if signed:\n",
    "            return torch.sign(outputs)\n",
    "        else:\n",
    "            return outputs\n",
    "\n",
    "# 合页损失函数\n",
    "class HingeLoss(nn.Module):\n",
    "    def __init__(self,lamb) -> None:\n",
    "        super(HingeLoss,self).__init__()\n",
    "        self.lamb = lamb\n",
    "\n",
    "    def forward(self,res_pre_linear_values,res_rel,parameters):\n",
    "        return torch.sum(torch.relu(1 - res_rel*res_pre_linear_values)) + self.lamb*torch.norm(parameters)**2\n",
    "    \n",
    "def train_svm(model, data_set, batch_size, lamb=1, epoch = 1000, learning_rate = 1e-3):\n",
    "    N,_ = data_set.shape\n",
    "    criterion = HingeLoss(lamb)\n",
    "    optim = torch.optim.SGD(model.parameters(),learning_rate,momentum=0) # 动量设置为0\n",
    "    \n",
    "    start = time.time()\n",
    "    loss_values = torch.zeros(epoch)\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        index = torch.randint(0,N,[batch_size]) # 随机选取batch条数据\n",
    "        data_i = data_set[index,:]\n",
    "        x_i = data_i[:,:-1].to(torch.float32)\n",
    "        y_i = data_i[:,-1:].to(torch.int32)\n",
    "        outputs = model(x_i,signed=False)\n",
    "        loss = criterion(outputs,y_i,model.linear.weight)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        model.eval()\n",
    "        loss_values[i] = loss.item()\n",
    "\n",
    "        print('\\r%5d/{}|{}{}|{:.2f}s  [Loss: %e]'.format(\n",
    "            epoch,\n",
    "            \"#\"*int((i+1)/epoch*50),\n",
    "            \" \"*(50-int((i+1)/epoch*50)),\n",
    "            time.time() - start) %\n",
    "            (i+1,\n",
    "            loss_values[i]), end = ' ', flush=True)\n",
    "    print(\"\\nTraining has been completed.\")\n",
    "    return loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1 = SVMLinear(\n",
    "    feature_num=train_data.shape[1]-1\n",
    ")\n",
    "svm2 = SVMLinear(\n",
    "    feature_num=train_data.shape[1]-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_svm1 = copy.deepcopy(train_data)\n",
    "train_data_svm2 = copy.deepcopy(train_data)\n",
    "train_data_svm1[train_data_svm1[:,-1].int() > 0,-1] = -1\n",
    "train_data_svm1[train_data_svm1[:,-1].int() == 0,-1] = 1\n",
    "train_data_svm2 = train_data_svm2[train_data_svm2[:,-1].int() > 0,:]\n",
    "train_data_svm2[train_data_svm2[:,-1].int() == 2,-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([124, 14])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_svm1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([88, 14])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_svm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1., -1.,\n",
       "         1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,\n",
       "         1.,  1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.,\n",
       "        -1.,  1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1.,  1.,\n",
       "        -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "        -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,\n",
       "        -1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
       "        -1., -1.,  1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1.],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_svm1[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,\n",
       "         1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,\n",
       "         1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n",
       "         1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1., -1.,\n",
       "        -1.,  1.,  1., -1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_svm2[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|5.86s  [Loss: 1.696882e+00]               \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "loss_values = train_svm(\n",
    "    model=svm1,\n",
    "    data_set=train_data_svm1,\n",
    "    batch_size=20,\n",
    "    lamb=1,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|6.81s  [Loss: 6.781775e-01]                       \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "loss_values = train_svm(\n",
    "    model=svm2,\n",
    "    data_set=train_data_svm2,\n",
    "    batch_size=20,\n",
    "    lamb=1,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_svm1 = svm1(\n",
    "    test_data[:,:-1].to(torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_svm2 = svm2(\n",
    "    test_data[pre_svm1[:,0] < 0,:-1].to(torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = pre_svm1[:,0]\n",
    "k = 0\n",
    "for i in range(predicts.shape[0]):\n",
    "    if predicts[i] > 0: predicts[i] = 0\n",
    "    elif predicts[i] < 0 and pre_svm2[k,0] > 0:\n",
    "        predicts[i] = 1\n",
    "        k += 1\n",
    "    else:\n",
    "        predicts[i] = 2\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 2, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 2, 2, 2, 0, 2, 2, 2, 2, 1, 0,\n",
       "        1, 2, 0, 1, 0, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "        0, 0, 2, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 0,\n",
       "        1, 2, 0, 1, 0, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:,-1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9444)\n"
     ]
    }
   ],
   "source": [
    "# 打印准确率\n",
    "print(torch.sum(predicts == test_data[:,-1].int()) / test_data.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 非线性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 观察数据分布\n",
    "train_data_nonlinear = copy.deepcopy(train_data)\n",
    "max = torch.max(train_data_nonlinear[:,:-1],dim=0).values\n",
    "min = torch.min(train_data_nonlinear[:,:-1],dim=0).values\n",
    "train_data_nonlinear[:,:-1] = (train_data_nonlinear[:,:-1] - min) / (max - min) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k1 = 1\n",
    "k2 = 2\n",
    "for i in range(train_data_nonlinear.shape[0]):\n",
    "    if train_data_nonlinear[i,-1].int() == 0:\n",
    "        plt.scatter(train_data_nonlinear[i,k1],train_data_nonlinear[i,k2],color='r')\n",
    "    else:\n",
    "        plt.scatter(train_data_nonlinear[i,k1],train_data_nonlinear[i,k2],color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjaUlEQVR4nO3df5AcZ33n8fdXK63MhkqQVjqfsa1dmZiACXcG9hx8VF3AGDD6wzIXBeSsHZkfpSADV3fUXSGjKo7ynQpD/jCXMnWOytgW0ZZ/oBSFcjHl+OdBVWzH6yv/5mTJslaWYvBiY+qEEv+QvvdHP4N6Z7tnema6Z7qnP6+qrp3pfrr76ad755np79PPY+6OiIjU15JBZ0BERAZLFYGISM2pIhARqTlVBCIiNaeKQESk5pYOOgPdWLVqlU9OTg46GyIilfLII4/8wt1XN8+vZEUwOTnJ7OzsoLMhIlIpZjaXNF+3hkREak4VgYhIzakiEBGpOVUEIiI1p4pARKTmcqkIzOxGM3vRzJ5MWW5m9hdmtt/MHjez98aWbTKzfWHalEd+JF8zMzA5CUuWRH9nZpLniUg15dV89GbgOuB7Kcs/Dpwdpj8A/ifwB2a2EvivwBTgwCNmtsfdf5lTvqRHMzOweTMcOxa9n5uDT38azOC1107O27w5ej09PZh8ikj3cvlF4O4/Bl5ukWQ98D2PPAi8xcxOAz4G3OXuL4cP/7uAi/LIk+Rj27aTlUDD66+frAQajh2L0opI9fQrRnA68Hzs/eEwL23+Ima22cxmzWx2fn6+sIzKQocOFZNWRMqjMsFid9/h7lPuPrV69aInpKUga9YUk1ZEyqNfFcER4MzY+zPCvLT5UhLbt8PY2MJ5y5bB6OjCeWNjUVoRqZ5+VQR7gD8NrYfeD/zK3V8A7gQ+amYrzGwF8NEwT0piehp27ICJiShAPDEBN90EN964cN6OHQoUi1RVLq2GzOwW4IPAKjM7TNQSaBmAu18P3AGsA/YDx4BPh2Uvm9l/Ax4Om7ra3VsFnWUApqeTP+T1wS8yHHKpCNz90jbLHfhCyrIbgRvzyIeIiHSuMsFiEREphioCEZGaU0UgIlJzqghERGpOFYGISM2pIhARqTlVBCIiNaeKQESk5lQRiMRowB2po7wGphGpvKRBeDTgjtSBfhGIBEmD8GjAHakDVQQiQdrAOhpwR4adKgKRIG1gHQ24I8NOFYFIkDQIjwbckTpQRSASJA3CowF3pA7UakgkJm0QHpFhlssvAjO7yMz2mtl+M9uasPxaM3s0TM+Y2SuxZcdjy/bkkR8REcmu518EZjYCfAf4CHAYeNjM9rj704007v6fYum/BLwntol/cvdze82HiIh0J49fBOcB+939gLu/BtwKrG+R/lLglhz2KyIiOcijIjgdeD72/nCYt4iZTQBrgXtjs08xs1kze9DMLknbiZltDulm5+fnc8j2cFHXCCLSrX4HizcCu939eGzehLsfMbOzgHvN7Al3f7Z5RXffAewAmJqa8v5ktxrUNYKI9CKPXwRHgDNj788I85JspOm2kLsfCX8PAPezMH4gGahrBBHpRR4VwcPA2Wa21sxGiT7sF7X+MbN3ACuAB2LzVpjZ8vB6FfAB4OnmdaU1dY0gIr3ouSJw9zeALwJ3Aj8Fbnf3p8zsajO7OJZ0I3Cru8dv67wTmDWzx4D7gGvirY0kG3WNICK9yOU5Ane/w93f7u5vc/ftYd7X3H1PLM3X3X1r03p/7+7vdvd/Hf5+N4/81E0vXSMoyCwi6mJiCHTbNUIjyDw3B+4ng8yqDETqxRbeqamGqakpn52dHXQ2Km9yMvrwbzYxAQcP9js3IlI0M3vE3aea5+sXQY0pyCwioIqg1hRkFhFQRVBr6n9fREAVwVDptAVQ5iCzmhZJwYb5EqvEsbl75ab3ve99Lgvt2uU+NuYetf+JprGxaH45NywSGeZLrGzHBsx6wmeqWg0NicJaAKlpkRRsmC+xsh1bWqshVQRDYsmS6PtGMzM4caKMGxaJDPMlVrZjU/PRIVdYCyA1LZKCDfMlVpVjU0VQcY1A1Nxc9C0jLpcWQGpaVCuDCGwO8yVWmWNLChyUfVKwOJIUiDKL/k5M5BiQ2rUr2qBZzhuWMhlkYHOYL7EyHRsKFg+fsgWipNp0PQ0/xQiGkLqIkDzpeqovVQQVVpVAlFSDrqf6UkVQYZUJREkl6Hqqr1wqAjO7yMz2mtl+M9uasPwKM5s3s0fD9LnYsk1mti9Mm/LIzyAMorVFo4uI8fGT8970puL3O0yynLdKdBGQg27HtZAhkBRB7mQCRoBngbOAUeAx4JymNFcA1yWsuxI4EP6uCK9XtNtn2VoNDbq1RZkeYa+SLGWn8pVhQlGthszsfODr7v6x8P6qUMF8I5bmCmDK3b/YtO6lwAfd/c/C+78E7nf3W1rts2ythgbZ2kItPbqXpexUvjJMimw1dDrwfOz94TCv2R+Z2eNmttvMzuxwXcxss5nNmtns/Px8DtnOzyBbW6ilR/eylJ3KV+qgX8HivwEm3f1fAXcBOzvdgLvvcPcpd59avXp17hnsxSBbW6ilR/eylJ3KV+ogj4rgCHBm7P0ZYd5vuPtL7v5qeHsD8L6s61bBIFtbqKVH97KUXVIas+h20TAHjqVmkgIHnUzAUqIg71pOBovf1ZTmtNjrTwAP+slg8XNEgeIV4fXKdvssW7DYfbCPkZfpEfaqyVJ2jTTxLjwUOJYqosguJsxsHfBtohZEN7r7djO7Oux0j5l9A7gYeAN4Gdji7v83rPsZ4KthU9vd/aZ2+ytbsFjqQYFjqTqNRyDSo7L1LS/SKfU1JNIjBY5lWKkiEMlIgXkZVqoIRDIqQxcMWbu7iKdbtSqahr2LDOmeYgQiFTEzA5s3w7FjJ+eNjS2ujJLSxSWtI/WgYLFIxWVttZSWrtU6Ug8KFotUXNbuLrJ0f6EuMiROFYFIRWRttZSlFZNaOkmcKgKRisjaaikpXbt1pN5UEZRANwOfNK9z5ZWLt1GXAVXqImurpelp2LQJRkai90uWwG/9Vn9aOumaq6ikfifKPpWxr6FudTPwSdI6zdOyZe6jo+oXp44GNZiOBvEpP4rsa6jfhqnVUDf912RpFZJGrUWG36D6RFJfTOWn5qMl1U3/NWnrZKF+cYbfoPpEUl9M5afmoyXVTf81vbT4UGuR4TeoPpHUF1N1qSIYsHYtQZKCb+1ahQAsWwajo+nbrYJWgceyBSXLlJ9+9okUP+6jR6t/zTWU6Xz2RVLgoOzTMAWL3dMHR2kVfGteZ8uWxduo8oA17Y69TEHJsuWnkaeiz33ScS9b5j4+Xs1rrqGM5zMvFDwwzUXA/yAamOYGd7+mafmXgc8RDUwzD3zG3efCsuPAEyHpIXe/uN3+hilG0Eqdg2+tjh3KVS51PU/DetzDelxQYLDYzEaAZ4CPAIeBh4FL3f3pWJoPAQ+5+zEz2wJ80N0/FZYddfc3d7LPulQEdQ6+tTp2KFe51PU8DetxD+txQbHB4vOA/e5+wN1fA24F1scTuPt97t7oC/FBokHqpY2yBN8Gcb+01bGXpVza7XfYg6TDetzDelyt5FERnA48H3t/OMxL81ngR7H3p5jZrJk9aGaXpK1kZptDutn5+fmeMlwVZRgIpdGl8dxc9C1pbi56X3Rl0OrYy1AucWXLT78M63EP63G1lBQ46GQCNhDFBRrvLweuS0l7GdEvguWxeaeHv2cBB4G3tdvnsAWLW9myxX1kJApYjYxE7/tpYmJh0KwxjYwUHxBsFfAsSyC8kY9GmUD3+SnLMXWiinnOomzHlVd+SAkW51ERnA/cGXt/FXBVQroLgZ8C/6LFtm4GNrTbZ10qgjK0XjBLrgiGsUVFp/I8P2U411JOeV4baRVBHsHipUTB4g8DR4iCxX/i7k/F0rwH2A1c5O77YvNXAMfc/VUzWwU8AKz3WKA5SV2CxWVovZC1O4thaFHRqTzPTxnOtZRTntdGYcFid38D+CJwJ9E3/tvd/Skzu9rMGk1B/xx4M/B9M3vUzPaE+e8EZs3sMeA+4Jp2lUCdZB2IpEhZHl6Deg50kuf5KcO5lnLqx7WxNI+NuPsdwB1N874We31hynp/D7w7jzwMozVrkr8J9LP1QqO74m3bogtvyRI4fnyweSqLPM9PGc61lFM/ro3adDFRxUfGy9J6YXo6+gl64gTs3Jn8C+Ho0e7KdGYGVq2K2mibRa8XbafLk1f0Oc/z/CRtywzWres+f/1SdDlX8X83T335HEgKHJR96jRYXOVAXNlaL7hHeRgf7z1ovGtX1CVB83ZGR2Pb6fLk9euc53l+tmxZHJwv+3VadDlX+X83T0W3GqpFN9QKxOUvjzJtFYj+zXa63FEVz7ny3P/t102tu6EehkBc2X4e51GmrdL+ZlmXO6riOVee+799idSiIqj6I+ODerq3lTzKNNOYC13uqIrnXHnu//YlUouKoCxB125t2wbHji2cd+xYNH9Q8ijT7dujcROajY7GttPljqp4zpXn/m9fgqTAQdmnbp4sLmPQNau0p3vNBpuvPMq0OfA8Pp6wnS53VMVzrjz3f/uD1s/jo87B4qpTwExkODVu+8Z/8Y+NwY4dJ5/hyVOtg8VVp5/HIsOpLLd9VRFUwPR09A1hYiJ6yGhiorhvDCLSP2VpFZVLFxNSvOlpffCLDJuydC2iXwR91PwswJVXdvFsQLcPFLRar2QPKWTNTl7ZzmM7JSvCvqjjMeetNLd9kyLIZZ+qOB5B0qPyHXfR0O3z9q3WK9kz/Fmzk1e289hOyYqwL+p4zEVRq6EuVbHVUC79+nfbfKjVelCqJklZDzGvllRFdpUxzK266njMwyCt1ZAqgj5ZsiT63tSOWdTLZ0cbablSm/Wgu20WJOshdlsU3e6v6G1UTR2PeRio+eiAZQ3+tEzX7fP2rdYr2TP8WbOTV7aL7CpjmLtBqOMxD7NcKgIzu8jM9prZfjPbmrB8uZndFpY/ZGaTsWVXhfl7zexjeeRnkNICaFlG+mobJOo2stRqvdJEqyJZs5NXtvPqKqNERdgXdTzmoZYUOOhkAkaAZ4GzgFHgMeCcpjRXAteH1xuB28Lrc0L65cDasJ2Rdvssa7C4XQCtOSi0ZUsHQaLGyuA+MhL9TVkpMfjUKiLV52f42+0ua3byynZeXWUkbaOooi3ylPW7/KV/SAkW51ERnA/cGXt/FXBVU5o7gfPD66XALwBrThtP12oqa0XQ+JxuniYmetxwB000yt6ao+z5y1NRx1pkGdbp/NRRkRXBBuCG2PvLgeua0jwJnBF7/yywCrgOuCw2/7vAhpT9bAZmgdk1a9YUXFzdKaxzuA5qmMIqo5yUPX95KupYiyzDOp2fOkqrCCoTLHb3He4+5e5Tq1evHnR2EhUWQOvgOfSyPLKepuz5y1NRx1pkGdbp/MhJeVQER4AzY+/PCPMS05jZUuB3gJcyrlsZhQXQ2tUwsQj1oSWTXMriRzzL0pqjTq1NijrWIsuwTudHYpJ+JnQyEd3zP0AU7G0Ei9/VlOYLLAwW3x5ev4uFweIDlCBY3E0QrINYbsf7/8mWzp4MPsqYn89PFtya2rKl83wUoez3oPMMgCYd6+hoNOZCr4FpxQikGxQVI4i2zTrgGaJ7/9vCvKuBi8PrU4DvA/uBfwDOiq27Lay3F/h4lv0VWRF084+Q5z9P2rZ+siXlEyrhpu4uLvU38evS/jOXtbVJER+C8WMdH3dftiy/62TQrYakegqtCPo9FVkRdBMsyzPA1vG2EiLUEzyXuI2RkQ7/uWv2iVB0oFSBWBm0tIpAXUw06ebR+Twft+94WwmdvizhOO3aAbQdBanfQyeVQNHdJqhbBhk0dTGRUTfBsjwDbB1vKyFCvcYOt91P21GQyjJ0Uh8VHShVIFbKShVBk25a/uTZWqjjbSUMX7b984fadmcBbZoEFtGOsOQd2BfdbUKh2y952UrJJd0vKvtU5lZDWdcpuseH+DYarZiSYgap2877hnZFmqMUHRbZtSsKGjeKYHw8h32klO2uLT+pU4hHMkDB4vLo92diq0FxUvebdyYVKXX3gs59SsuxMStvyzEZjLSKQMHiARjEoB4zM7BpExw/3sF+Z2aimMChQ9GN7O3buw8UK1IKFHTuE8p2kueYYzLf/UjlaWCaEhnUZ+JAP4s1pBVQ0DnooOVYzepdaaJWQyUyqNYjA221og7sgYLOQQctx9RCSZKoIohJaniRR2OM5m2sW7f4M9Esmp9bxhNk/SzOfMydFE5C66Z+PJMQz+KqVdGU57nsdBuF1IcZW47VsN6VrJICB2WfiggWp/UL02uXAGnBwQ9/ePFDwV0F8zqMPmYZFCbT5irQCqhVkDzPc9npIffrge2aPRguGaBgcWtpt7CTdHJbO227IyMdBm6bNQK5aZnu8t575lv5Fbjnn+Wc5nEuS3TIIi0pWNxGWhAvSScBt062m3nbSd0/dLWhxTIHMyvQCihL2edxLkt0yCItKVjcRidBtDzSjoz0sO2k7h+62lD21RbNr0B/CVmykse5LNEhi3RFFUGQFMQbHYVlyxbO6zTglhYc3Ly5h6Bhu24eeogKZg5mbt8eFVDc6GipopFJxxKX17ks0SGLdCcpcFD2qagni5OCa70G3Fp1KdD1ttOe0m08qdtjVDAtX/H5Xxrf5W+MNEXSly0rXUSyeTyAPAaFqXwAdigOQrqBupjov8Ia1mTZcM7/7M27fI6J9IpIyqsCrb2kOIVUBMBK4C5gX/i7IiHNucADwFPA48CnYstuBp4DHg3TuVn2W5WKoNDuddr1WpfzP3vzsRxn8YA4DlF+pLzU51OtpVUEPbUaMrNvAS+7+zVmtjVUBF9pSvP26A6U7zOztwKPAO9091fM7Gbgf7n77k72W5UuJvrWyqS5T6CjR+Gllxan66GdY/OxPMckk6gtZeWo6VOtFdVqaD2wM7zeCVzSnMDdn3H3feH1PwIvAqt73G8l9KWVSaMp6dxc9A8+N5dcCUBPYwk05/mrbOfXKHJaOWr6JAl6rQhOdfcXwuufAae2Smxm5wGjRIPVN2w3s8fN7FozW95i3c1mNmtms/Pz8z1muz/60sokS1PShh7+2ZuP5Ram+eKyHRwd72+XEdIjNX2SJEn3i+ITcDfwZMK0HnilKe0vW2znNGAv8P6meQYsJ/pF8bV2+fEKxQjc+9BAI2Hw+lz6U0igxiZDQieytigoWLwXOM1jH/Qp6X4b+D/Ahhbb+iBRvKDyFUHW/7O26bJsKC34Nz6uf3YRWaCoiuDPga3h9VbgWwlpRoF7gP+YsKxRiRjwbeCaLPstc0WQtcFO23S5bUhEJJJWEfTaamgcuB1YA8wBn3T3l81sCvi8u3/OzC4DbiJqPtpwhbs/amb3EgWOjaj56Ofd/Wi7/Za51VDWjslS040f5eCbf7+zzuTyHElMRIaWOp3rk6yt81LTcYITpHRElLQhEZGM1Olcn2RtnZeajjZNPNesyWe0HBGRQBVBzrK2zktMx6/ZzlfTNz42Fg1j1vzcwObNcOWVqhxEpCuqCHKWdUTGxHTjVzHNLckbbmzojjsWPzdw7Bhcf/3CyuGyy6JxGVUhiEgbihGUSdKAM2NjC2uSTke6WbYMbrpJwWMRUYygErL8nOj06eDXX4fLL9ctIxFJpYqgSV/jsLGdHV01yX9YNcOSy6eZ5CAzf3Uiaiba/E2+3WgrSRpPGDTiCaoMBibT9aXGANJvSQ8XlH0qcmCavj2blbCzo4z5pexqv9/GE8eNbp+zdDGhLocHLtP1pQcEpUAU8UDZoBQVI8j6MFiROzvIBGs5mG2/aRluR88iDESm66uvF6HUjR4oy6CvXbWn7OwExggnsu2308Bxgz5UBiLT9aXxAqRAChZn0Neu2lM2eog17ZK03UZL6nJ4YDJdXxovQAZAFUFMX7tqT9jZrxnjq2zPvt9OA8fj4xozYIAyXV8aL0AGISlwUPapyN5H+9pVe2xn/298wr80vqvz/cYzPD4eTc2v1Q11aWS6vjRegBQEBYtFROpNMQIREUmkimCY6cEkEcmgp4rAzFaa2V1mti/8XZGS7riZPRqmPbH5a83sITPbb2a3mdloL/mRmEa/Rc29lKoyEJEmvf4i2Arc4+5nEw1HuTUl3T+5+7lhujg2/5vAte7+u8Avgc/2mJ/CVO7L9bZtyb2Ubtt28n3lDkpEitBrRbAe2Ble7wQuybqimRlwAbC7m/X7qZJfrg+lDHDTmF/JgxKRIvRaEZzq7i+E1z8DTk1Jd4qZzZrZg2Z2SZg3Drzi7m+E94eB09N2ZGabwzZm5+fne8x2Z7J8uS6ddg8mVfKgRKQIbSsCM7vbzJ5MmNbH04U2qmltUSdCk6U/Ab5tZm/rNKPuvsPdp9x9avXq1Z2u3pO07nzSvnSXQrsHk9r9YhCR2ljaLoG7X5i2zMx+bmanufsLZnYa8GLKNo6EvwfM7H7gPcBfA28xs6XhV8EZwJEujqFQMzNRNy9Jj1uU+qn/xtPD27ZFH+5r1kSVQGP+mjXJNVypD0pEitDrraE9wKbwehPww+YEZrbCzJaH16uADwBPh18Q9wEbWq0/aNu2pfcBVvqn/qeno87lTiSMbbBuXXQQcerKQKSWeq0IrgE+Ymb7gAvDe8xsysxuCGneCcya2WNEH/zXuPvTYdlXgC+b2X6imMF3e8xP7tLulLhXuMuemRnYuXNhDWcGmzZV+KBEpFvqYqKNoewefigPSkTaURcTXRrKziAVKBaRGFUEbWQZT75y1Oe9iMSoIsigVcy1kobyZ46IdEsVQdV1003EUP7MEZFutX2OQEqs0U1E4wnhRjcR0P5DfXpaH/wiAugXQbWpmwgRyYEqgipT6x8RyYEqgipT6x8RyYEqgipT6x8RyYEqgipT6x8RyYFaDVWdWv+ISI/0i0BEpOZUEYiI1JwqAhGRmlNFICJSc6oIRERqrqeKwMxWmtldZrYv/F2RkOZDZvZobPpnM7skLLvZzJ6LLTu3l/yIiEjnev1FsBW4x93PBu4J7xdw9/vc/Vx3Pxe4ADgG/F0syX9pLHf3R3vMj4iIdKjXimA9sDO83glc0ib9BuBH7n6sTToREemTXiuCU939hfD6Z8CpbdJvBG5pmrfdzB43s2vNbHnaima22cxmzWx2fn6+hyyLiEhc24rAzO42sycTpvXxdO7ugLfYzmnAu4E7Y7OvAt4B/BtgJfCVtPXdfYe7T7n71OrVq9tlW0REMmpbEbj7he7++wnTD4Gfhw/4xgf9iy029UngB+7+emzbL3jkVeAm4LzeDkd+o5uRy0Sklnq9NbQH2BRebwJ+2CLtpTTdFopVIkYUX3iyx/wInBy5bG4O3E+OXKbKQEQS9FoRXAN8xMz2AReG95jZlJnd0EhkZpPAmcD/blp/xsyeAJ4AVgH/vcf8CGjkMhHpiEW39qtlamrKZ2dnB52N8lqyJPol0MwMTpzof35EpBTM7BF3n2qeryeLh1GWkcsUQxCRQBXBMGo3cpliCCISo4pgGLUbuUwxBBGJUYygjhRDEKklxQjkpCwxBBGpDVUEddQuhiAitaKKoI7axRBEpFaWDjoDMiDT0/rgFxFAvwhERGpPFUEd6OExEWlBt4aGXePhscZzA42Hx0C3hkQE0C+C4aeHx0SkDVUEw+7Qoc7mi0jtqCIYdnp4TETaUEUw7PTwmIi0oYpg2OnhMRFpo6eKwMz+2MyeMrMTZraoI6NYuovMbK+Z7TezrbH5a83soTD/NjMb7SU/eRqqFpfT03DwYNSh3MGDqgREZIFefxE8Cfx74MdpCcxsBPgO8HHgHOBSMzsnLP4mcK27/y7wS+CzPeYnF+quX0TqpKeKwN1/6u572yQ7D9jv7gfc/TXgVmB9GLD+AmB3SLeTaAD7gVOLSxGpk37ECE4Hno+9PxzmjQOvuPsbTfMTmdlmM5s1s9n5+fnCMgtqcSki9dK2IjCzu83syYRpfT8y2ODuO9x9yt2nVq9eXei+1OJSROqkbRcT7n5hj/s4ApwZe39GmPcS8BYzWxp+FTTmD9z27Qt7ZQC1uBSR4dWPW0MPA2eHFkKjwEZgj0djZN4HbAjpNgE/7EN+2lKLSxGpk16bj37CzA4D5wN/a2Z3hvlvNbM7AMK3/S8CdwI/BW5396fCJr4CfNnM9hPFDL7bS37ypBaXIlIXGrxeRKQmNHi9iIgkUkUgIlJzqghERGpOFYGISM1VMlhsZvPAXJerrwJ+kWN28qJ8dUb56ozy1ZlhzdeEuy96IreSFUEvzGw2KWo+aMpXZ5SvzihfnalbvnRrSESk5lQRiIjUXB0rgh2DzkAK5aszyldnlK/O1CpftYsRiIjIQnX8RSAiIjGqCEREam4oKwIz+2Mze8rMTphZalMrM7vIzPaa2X4z2xqbv9bMHgrzbwvdZ+eRr5VmdpeZ7Qt/VySk+ZCZPRqb/tnMLgnLbjaz52LLzu1XvkK647F974nNH2R5nWtmD4Tz/biZfSq2LNfySrteYsuXh+PfH8pjMrbsqjB/r5l9rJd8dJGvL5vZ06F87jGzidiyxHPap3xdYWbzsf1/LrZsUzjv+8xsU5/zdW0sT8+Y2SuxZYWUl5ndaGYvmtmTKcvNzP4i5PlxM3tvbFnvZeXuQzcB7wR+D7gfmEpJMwI8C5wFjAKPAeeEZbcDG8Pr64EtOeXrW8DW8Hor8M026VcCLwNj4f3NwIYCyitTvoCjKfMHVl7A24Gzw+u3Ai8Ab8m7vFpdL7E0VwLXh9cbgdvC63NC+uXA2rCdkT7m60Oxa2hLI1+tzmmf8nUFcF3CuiuBA+HvivB6Rb/y1ZT+S8CNfSivfwe8F3gyZfk64EeAAe8HHsqzrIbyF4G7/9Td97ZJdh6w390PuPtrwK3AejMz4AJgd0i3E7gkp6ytD9vLut0NwI/c/VibdL3qNF+/Mejycvdn3H1feP2PwItAEWOZJl4vLfK7G/hwKJ/1wK3u/qq7PwfsD9vrS77c/b7YNfQg0WiARctSXmk+Btzl7i+7+y+Bu4CLBpSvS4Fbctp3Knf/MdGXvjTrge955EGi0R1PI6eyGsqKIKPTgedj7w+HeePAKx4NqBOfn4dT3f2F8PpnwKlt0m9k8UW4Pfw0vNbMlvc5X6eY2ayZPdi4XUWJysvMziP6lvdsbHZe5ZV2vSSmCeXxK6LyybJukfmK+yzRN8uGpHPaz3z9UTg/u82sMaRtKcor3EJbC9wbm11UebWTlu9cyqrtmMVlZWZ3A/8yYdE2dx/YkJet8hV/4+5uZqltd0Nt/26ikd0ariL6QBwlak/8FeDqPuZrwt2PmNlZwL1m9gTRh13Xci6vvwI2ufuJMLvr8hpGZnYZMAX8YWz2onPq7s8mbyF3fwPc4u6vmtmfEf2auqBP+85iI7Db3Y/H5g2yvApT2YrA3S/scRNHgDNj788I814i+tm1NHyra8zvOV9m9nMzO83dXwgfXC+22NQngR+4++uxbTe+Hb9qZjcB/7mf+XL3I+HvATO7H3gP8NcMuLzM7LeBvyX6EvBgbNtdl1eCtOslKc1hM1sK/A7R9ZRl3SLzhZldSFS5/qG7v9qYn3JO8/hga5svd38p9vYGophQY90PNq17fw55ypSvmI3AF+IzCiyvdtLynUtZ1fnW0MPA2Ra1eBklOul7PIrA3Ed0fx5gE5DXL4w9YXtZtrvo3mT4MGzcl78ESGxhUES+zGxF49aKma0CPgA8PejyCufuB0T3T3c3LcuzvBKvlxb53QDcG8pnD7DRolZFa4GzgX/oIS8d5cvM3gP8JXCxu78Ym594TvuYr9Niby8mGtMcol/BHw35WwF8lIW/jAvNV8jbO4iCrw/E5hVZXu3sAf40tB56P/Cr8EUnn7IqIgI+6An4BNG9sleBnwN3hvlvBe6IpVsHPENUo2+LzT+L6B91P/B9YHlO+RoH7gH2AXcDK8P8KeCGWLpJopp+SdP69wJPEH2g7QLe3K98Af827Pux8PezZSgv4DLgdeDR2HRuEeWVdL0Q3Wq6OLw+JRz//lAeZ8XW3RbW2wt8POfrvV2+7g7/B43y2dPunPYpX98Angr7vw94R2zdz4Ry3A98up/5Cu+/DlzTtF5h5UX0pe+FcC0fJorlfB74fFhuwHdCnp8g1hoyj7JSFxMiIjVX51tDIiKCKgIRkdpTRSAiUnOqCEREak4VgYhIzakiEBGpOVUEIiI19/8BSgpNW9a9t30AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k1 = 1\n",
    "k2 = 3\n",
    "for i in range(train_data_nonlinear.shape[0]):\n",
    "    if train_data_nonlinear[i,-1].int() == 0:\n",
    "        plt.scatter(train_data_nonlinear[i,k1],train_data_nonlinear[i,k2],color='r')\n",
    "    else:\n",
    "        plt.scatter(train_data_nonlinear[i,k1],train_data_nonlinear[i,k2],color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高斯核非线性SVM\n",
    "class SVMNonLinear(nn.Module):\n",
    "    def __init__(self,feature_num,kernel_data) -> None:\n",
    "        super(SVMNonLinear,self).__init__()\n",
    "        self.feature_num = feature_num\n",
    "        self.kernel_features = kernel_data[:,:-1].to(torch.float32)\n",
    "        self.kernel_labels = kernel_data[:,-1].to(torch.int32)\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_num)\n",
    "        self.linear = nn.Linear(feature_num+kernel_data.shape[0],1)\n",
    "        self.kernel_params = nn.Parameter(torch.rand(1)+5,requires_grad=True) # 核函数标准差\n",
    "    \n",
    "    def forward(self, x, signed = True):\n",
    "        B,d = x.shape\n",
    "        assert B > 0 and d == self.feature_num\n",
    "        # 归一化特征\n",
    "        normed_data = self.batch_norm(x)\n",
    "        normed_kernel_data = self.batch_norm(self.kernel_features)\n",
    "        kernel_features = torch.exp(-torch.mm(normed_data,normed_kernel_data.T) / self.kernel_params**2) * self.kernel_labels\n",
    "        outputs = self.linear(torch.cat([normed_data,kernel_features],dim=1)) # 核方法特征和原特征结合\n",
    "        if signed:\n",
    "            return torch.sign(outputs)\n",
    "        else:\n",
    "            return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_data_size = 30\n",
    "kernel_data_svm1 = copy.deepcopy(train_data)[:kernel_data_size]\n",
    "kernel_data_svm2 = copy.deepcopy(train_data)\n",
    "kernel_data_svm1[kernel_data_svm1[:,-1].int() > 0,-1] = -1\n",
    "kernel_data_svm1[kernel_data_svm1[:,-1].int() == 0,-1] = 1\n",
    "kernel_data_svm2 = kernel_data_svm2[kernel_data_svm2[:,-1].int() > 0,:][:kernel_data_size]\n",
    "kernel_data_svm2[kernel_data_svm2[:,-1].int() == 2,-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 14])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_data_svm1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 14])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_data_svm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1., -1.,\n",
       "         1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,\n",
       "         1.,  1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_data_svm1[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,\n",
       "         1., -1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_data_svm2[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1 = SVMNonLinear(\n",
    "    feature_num=train_data.shape[1]-1,\n",
    "    kernel_data=kernel_data_svm1\n",
    ")\n",
    "svm2 = SVMNonLinear(\n",
    "    feature_num=train_data.shape[1]-1,\n",
    "    kernel_data=kernel_data_svm2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_svm1 = copy.deepcopy(train_data)\n",
    "train_data_svm2 = copy.deepcopy(train_data)\n",
    "train_data_svm1[train_data_svm1[:,-1].int() > 0,-1] = -1\n",
    "train_data_svm1[train_data_svm1[:,-1].int() == 0,-1] = 1\n",
    "train_data_svm2 = train_data_svm2[train_data_svm2[:,-1].int() > 0,:]\n",
    "train_data_svm2[train_data_svm2[:,-1].int() == 2,-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|7.35s  [Loss: 7.634701e-01]                                \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "loss_values = train_svm(\n",
    "    model=svm1,\n",
    "    data_set=train_data_svm1,\n",
    "    batch_size=20,\n",
    "    lamb=1,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|7.21s  [Loss: 7.282843e-01]                                  \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "loss_values = train_svm(\n",
    "    model=svm2,\n",
    "    data_set=train_data_svm2,\n",
    "    batch_size=20,\n",
    "    lamb=1,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_svm1 = svm1(\n",
    "    test_data[:,:-1].to(torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_svm2 = svm2(\n",
    "    test_data[pre_svm1[:,0] < 0,:-1].to(torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = pre_svm1[:,0]\n",
    "k = 0\n",
    "for i in range(predicts.shape[0]):\n",
    "    if predicts[i] > 0: predicts[i] = 0\n",
    "    elif predicts[i] < 0 and pre_svm2[k,0] > 0:\n",
    "        predicts[i] = 1\n",
    "        k += 1\n",
    "    else:\n",
    "        predicts[i] = 2\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 2, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 2, 2, 2, 0, 2, 2, 2, 2, 1, 0,\n",
       "        1, 2, 0, 1, 0, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "        0, 0, 2, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 0,\n",
       "        1, 2, 0, 1, 0, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:,-1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9444)\n"
     ]
    }
   ],
   "source": [
    "# 打印准确率\n",
    "print(torch.sum(predicts == test_data[:,-1].int()) / test_data.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层非线性感知机（神经网络）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,feature_num,class_num,hidden_dim=20,layer_num=2) -> None:\n",
    "        super(MLP,self).__init__()\n",
    "        self.feature_num = feature_num\n",
    "        self.class_num = class_num\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_num = layer_num\n",
    "        self.model = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [(\"input_layer\",\n",
    "                    nn.Sequential(\n",
    "                        nn.BatchNorm1d(feature_num),\n",
    "                        nn.Linear(feature_num,hidden_dim),\n",
    "                        nn.Tanh()\n",
    "                    ))] + \n",
    "                [(\"hidden_layer_\"+str(i+1),\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(hidden_dim,hidden_dim),\n",
    "                        nn.Tanh()\n",
    "                    )) for i in range(layer_num-1)] + \n",
    "                [(\"output_layer\",\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(hidden_dim,class_num),\n",
    "                        nn.Softmax(dim=1)\n",
    "                    ))]\n",
    "            )\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(\n",
    "    feature_num=train_data.shape[1]-1,\n",
    "    class_num=3,\n",
    "    hidden_dim=30,\n",
    "    layer_num=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|7.64s  [Loss: 2.821501e-01]                     \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "loss_values = train(\n",
    "    model=mlp,\n",
    "    data_set=train_data,\n",
    "    batch_size=20,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = mlp(\n",
    "    test_data[:,:-1].float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = torch.argmax(predicts,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 2, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 2, 1, 0,\n",
       "        1, 2, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "        0, 0, 2, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 0,\n",
       "        1, 2, 0, 1, 0, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:,-1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9630)\n"
     ]
    }
   ],
   "source": [
    "# 打印准确率\n",
    "print(torch.sum(predicts == test_data[:,-1].int()) / test_data.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
