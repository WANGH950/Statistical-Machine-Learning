{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计机器学习第二次作业\n",
    "### 葡萄酒品种分类——基于Pytorch\n",
    "王恒 计算数学 220220934161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x182916c6e10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "import time\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "data =  datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = torch.tensor(data.data)\n",
    "data_labels = torch.tensor(data.target)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([178, 13])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([178, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = torch.cat([data_features,data_labels],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = data_set.shape[0]\n",
    "alpha = 0.6\n",
    "train_len = int(length*alpha)\n",
    "test_len = length - train_len\n",
    "train_data, test_data = torch.utils.data.random_split(data_set,[train_len,test_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_data = torch.tensor([item.numpy() for item in train_data])\n",
    "test_data = torch.tensor([item.numpy() for item in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([106, 14])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([72, 14])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class NaiveBayes(nn.Module):\n",
    "    def __init__(self, n, full_labels, S, lamb) -> None:\n",
    "        super(NaiveBayes,self).__init__()\n",
    "        # 归一化参数\n",
    "        self.max = None\n",
    "        self.min = None\n",
    "        self.n = n # 特征数量\n",
    "        self.full_labels = full_labels # 所有标签\n",
    "        self.K = len(full_labels) # 标签数量\n",
    "        self.lamb = lamb # 贝叶斯估计参数lambda\n",
    "        self.S = S # 每个特征分划区间数，这里默认都为S\n",
    "        self.cond_prob = torch.zeros([self.K,self.n,S]) # 条件概率\n",
    "        self.pre_prob = torch.zeros([self.K]) # 先验概率\n",
    "\n",
    "    def forward(self, features):\n",
    "        B,n = features.shape\n",
    "        assert n == self.n\n",
    "        post_prob = torch.ones([B,1])*self.pre_prob\n",
    "        # 归一化\n",
    "        features = (features - self.min) / (self.max - self.min) * 2 - 1\n",
    "        delta_x = 2 / (self.S - 2)\n",
    "        for i in range(B):\n",
    "            for j in range(self.K):\n",
    "                for k in range(n):\n",
    "                    if features[i,k] < -1: post_prob[i,j] *= self.cond_prob[j,k,0]\n",
    "                    elif features[i,k] >= 1: post_prob[i,j] *= self.cond_prob[j,k,-1]\n",
    "                    else:\n",
    "                        for h in range(self.S-2):\n",
    "                            l = -1 + h * delta_x\n",
    "                            r = l + delta_x\n",
    "                            if features[i,k] >= l and features[i,k] < r:\n",
    "                                post_prob[i,j] *= self.cond_prob[j,k,h+1]\n",
    "                                break\n",
    "        return self.full_labels[torch.argmax(post_prob,dim=1)]\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        # 计算先验概率\n",
    "        N,_ = train_data.shape\n",
    "        self.max = torch.max(train_data[:,:-1],dim=0).values\n",
    "        self.min = torch.min(train_data[:,:-1],dim=0).values\n",
    "        train_data[:,:-1] = (train_data[:,:-1] - self.min) / (self.max - self.min) * 2 - 1\n",
    "        features = train_data[:,:-1] # 特征\n",
    "        labels = train_data[:,-1:].int() # 标签\n",
    "        delta_x = 2 / (self.S - 2)\n",
    "        for i in range(self.K):\n",
    "            labels_i = labels == self.full_labels[i]\n",
    "            self.pre_prob[i] = (labels_i.sum() + self.lamb) / (N + self.K*self.lamb)\n",
    "            for j in range(self.n):\n",
    "                self.cond_prob[i,j,0] = 1 / self.S\n",
    "                for k in range(self.S-1):\n",
    "                    l = -1 + k * delta_x\n",
    "                    r = l + delta_x\n",
    "                    features_ij = features[labels_i[:,0],j]\n",
    "                    features_ijk = features_ij[(features_ij>=l)*(features_ij<r)]\n",
    "                    self.cond_prob[i,j,k+1] = (features_ijk.shape[0] + self.lamb) / (labels_i.sum() + self.S*self.lamb)\n",
    "        return self.pre_prob, self.cond_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayse = NaiveBayes(\n",
    "    n=train_data.shape[1]-1,\n",
    "    full_labels=torch.tensor([0,1,2]),\n",
    "    S=10,\n",
    "    lamb=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "_,_ = naive_bayse.fit(\n",
    "    train_data = copy.deepcopy(train_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "predicts = naive_bayse(\n",
    "    copy.deepcopy(test_data[:,:-1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 0, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 1, 2, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:,-1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9583)\n"
     ]
    }
   ],
   "source": [
    "# 打印准确率\n",
    "print(torch.sum(predicts == test_data[:,-1].int()) / test_data.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义模型（ID3算法）\n",
    "# class Node():\n",
    "#     def __init__(self, father = None, childrens = [], mark = None) -> None:\n",
    "#         super(Node,self).__init__()\n",
    "#         self.father = father\n",
    "#         self.childrens = childrens\n",
    "#         self.mark = mark\n",
    "#         self.split = []\n",
    "    \n",
    "#     def is_leaf(self):\n",
    "#         if self.mark is None:\n",
    "#             return False\n",
    "#         else:\n",
    "#             return True\n",
    "\n",
    "# class DecisionTree(nn.Module):\n",
    "#     def __init__(self, full_features, full_labels, S, esplison = 0.001) -> None:\n",
    "#         super(DecisionTree,self).__init__()\n",
    "#         self.esplison = esplison\n",
    "#         self.S = S # 特征划分数\n",
    "#         self.full_features = full_features\n",
    "#         self.feature_num = len(full_features)\n",
    "#         self.full_labels = full_labels\n",
    "#         self.K = len(full_labels)\n",
    "#         # 归一化参数\n",
    "#         self.min = None\n",
    "#         self.max = None\n",
    "#         self.Tree = Node()\n",
    "\n",
    "#     def create_tree(self,D,A,node = None,root = None):\n",
    "#         if node is None: \n",
    "#             node = self.Tree\n",
    "#             root = self.Tree\n",
    "#             # 归一化\n",
    "#             self.max = torch.max(D[:,:-1],dim=0).values\n",
    "#             self.min = torch.min(D[:,:-1],dim=0).values\n",
    "#             D[:,:-1] = (D[:,:-1] - self.min) / (self.max - self.min) * 2 - 1\n",
    "#         features = D[:,:-1]\n",
    "#         labels = D[:,-1:]\n",
    "#         # 只有一种标签时候直接返回\n",
    "#         if torch.unique(labels).shape[0] == 1:\n",
    "#             node.mark = D[0,-1]\n",
    "#             return root\n",
    "#         # 标签数量为空时直接返回\n",
    "#         elif len(A) == 0:\n",
    "#             count = torch.bincount(labels)\n",
    "#             mark = torch.argmax(count)\n",
    "#             node.mark = mark\n",
    "#             return root\n",
    "#         else:\n",
    "#             # 计算各特征的信息增益，选择最大信息增益特征\n",
    "#             g = self.information_gain(D,A[0])\n",
    "#             Ag = 0\n",
    "#             for i in range(len(A) - 1):\n",
    "#                 gi = self.information_gain(D,A[i+1])\n",
    "#                 if gi > g:\n",
    "#                     g = gi\n",
    "#                     Ag = i+1\n",
    "#             # 达到精度返回\n",
    "#             if g < self.esplison:\n",
    "#                 count = torch.bincount(labels)\n",
    "#                 mark = torch.argmax(count)\n",
    "#                 node.mark = mark\n",
    "#                 return root\n",
    "#             # 未达到精度继续递归生成子节点\n",
    "#             else:\n",
    "#                 l = None\n",
    "#                 r = -1\n",
    "#                 delta_x = 2 / (self.S - 2)\n",
    "#                 feature_i = features[:,Ag]\n",
    "#                 Ai = copy.deepcopy(A)\n",
    "#                 Ai[Ag] = False\n",
    "#                 for i in range(self.S):\n",
    "#                     if i == self.S - 1: r = None\n",
    "#                     if l is None:\n",
    "#                         index = feature_i < r\n",
    "#                         # 当前数据不空\n",
    "#                         if index.sum() > 0:\n",
    "#                             node.split.append(lambda x: x < r) # 用于判别并分划当前特征\n",
    "#                             Di = D[index,:] # Di一定非空\n",
    "#                             assert Di.shape[0] > 0\n",
    "#                             nodei = Node(father=node)\n",
    "#                             # 递归处理子节点\n",
    "#                             self.create_tree(Di,Ai,nodei,root)\n",
    "#                             node.childrens.append(nodei)\n",
    "#                             l = r\n",
    "#                             r = r + delta_x\n",
    "#                     elif r is None:\n",
    "#                         index = feature_i >= l\n",
    "#                         # 当前数据不空\n",
    "#                         if index.sum() > 0:\n",
    "#                             node.split.append(lambda x: x < r) # 用于判别并分划当前特征\n",
    "#                             Di = D[index,:] # Di一定非空\n",
    "#                             assert Di.shape[0] > 0\n",
    "#                             nodei = Node(father=node)\n",
    "#                             # 递归处理子节点\n",
    "#                             self.create_tree(Di,Ai,nodei,root)\n",
    "#                             node.childrens.append(nodei)\n",
    "#                             l = r\n",
    "#                             r = r + delta_x\n",
    "                        \n",
    "                            \n",
    "                \n",
    "\n",
    "#     # 计算经验熵\n",
    "#     def empirical_entropy(self,D):\n",
    "#         labels = data_set[:,-1:]\n",
    "#         HD = 0\n",
    "#         for j in range(self.K):\n",
    "#             labels_j = labels == self.full_labels[j]\n",
    "#             HD -= labels_j.sum() / D * torch.log2(labels_j.sum() / D)\n",
    "#         return HD\n",
    "\n",
    "#     # 计算A对于数据集D的经验条件熵\n",
    "#     def empirical_cond_entropy(self,D,A):\n",
    "#         D_ = D.shape[0]\n",
    "#         index = self.full_features == A\n",
    "#         features = D[:,:-1]\n",
    "#         labels = D[:,-1:]\n",
    "#         DA = features[:,index]\n",
    "#         DAi = DA[DA < -1,None]\n",
    "#         Li = labels[DA < -1,:]\n",
    "#         HDA = len(DAi) / D_ * self.empirical_entropy(torch.cat([DAi,Li],dim=1))\n",
    "#         DAi = DA[DA >= 1,None]\n",
    "#         Li = labels[DA >= 1,:]\n",
    "#         HDA += len(DAi) / D_ * self.empirical_entropy(torch.cat([DAi,Li],dim=1))\n",
    "#         delta_x = 2 / (self.S - 2)\n",
    "#         for i in range(self.S - 2):\n",
    "#             l = -1 + i * delta_x\n",
    "#             r = l + delta_x\n",
    "#             index_i = (DA >= l) * (DA < r)\n",
    "#             DAi = DA[index_i,None]\n",
    "#             Li = labels[index_i,:]\n",
    "#             HDA += len(DAi) / D_ * self.empirical_entropy(torch.cat([DAi,Li],dim=1))\n",
    "#         return HDA\n",
    "\n",
    "#     # 计算信息增益\n",
    "#     def information_gain(self,data_set,feature):\n",
    "#         if self.min is None or self.max is None:\n",
    "#             self.max = torch.max(train_data[:,:-1],dim=0).values\n",
    "#             self.min = torch.min(train_data[:,:-1],dim=0).values\n",
    "#         # 特征归一化到[-1,1]\n",
    "#         train_data[:,:-1] = (train_data[:,:-1] - self.min) / (self.max - self.min) * 2 - 1\n",
    "\n",
    "#         index = self.full_features == feature\n",
    "#         D,_ = data_set\n",
    "#         assert torch.sum(index) == 1 and D > 1\n",
    "#         # 计算经验熵\n",
    "#         HD = self.empirical_entropy(data_set)\n",
    "#         # 计算feature对于数据集data_set的经验条件熵\n",
    "#         HDA = self.empirical_cond_entropy(data_set,feature)\n",
    "#         return HD - HDA\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic 回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic(nn.Module):\n",
    "    def __init__(self,feature_num,class_num) -> None:\n",
    "        super(Logistic,self).__init__()\n",
    "        self.feature_num = feature_num\n",
    "        self.class_num = class_num\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.BatchNorm1d(feature_num),\n",
    "            nn.Linear(feature_num,class_num-1,bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,d = x.shape\n",
    "        assert d == self.feature_num and B > 0\n",
    "        y = torch.cat([torch.exp(self.linear(x)),torch.ones([B,1])],dim=1)\n",
    "        y = y / torch.sum(y,dim=1,keepdim=True)\n",
    "        return y\n",
    "    \n",
    "# 负对数似然损失函数\n",
    "class NLLLoss(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self,y_pre,y_rel):\n",
    "        assert y_pre.shape == y_rel.shape\n",
    "        loss = -torch.log(y_pre)*y_rel\n",
    "        return torch.sum(loss)\n",
    "\n",
    "def train(model, data_set, batch_size, epoch = 1000, learning_rate = 1e-3):\n",
    "    N,_ = data_set.shape\n",
    "    criterion = NLLLoss()\n",
    "    optim = torch.optim.SGD(model.parameters(),learning_rate,momentum=0) # 动量设置为0\n",
    "    \n",
    "    start = time.time()\n",
    "    loss_values = torch.zeros(epoch)\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        index = torch.randint(0,N,[batch_size]) # 随机选取batch条数据\n",
    "        data_i = data_set[index,:]\n",
    "        x_i = data_i[:,:-1].to(torch.float32)\n",
    "        y_i = nn.functional.one_hot(data_i[:,-1].to(torch.int64),num_classes=model.class_num)\n",
    "        outputs = model(x_i)\n",
    "        loss = criterion(outputs,y_i)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        model.eval()\n",
    "        loss_values[i] = loss.item()\n",
    "\n",
    "        print('\\r%5d/{}|{}{}|{:.2f}s  [Loss: %e]'.format(\n",
    "            epoch,\n",
    "            \"#\"*int((i+1)/epoch*50),\n",
    "            \" \"*(50-int((i+1)/epoch*50)),\n",
    "            time.time() - start) %\n",
    "            (i+1,\n",
    "            loss_values[i]), end = ' ', flush=True)\n",
    "    print(\"\\nTraining has been completed.\")\n",
    "    return loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Logistic(\n",
    "    feature_num=train_data.shape[1]-1,\n",
    "    class_num=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6/2000|                                                  |0.33s  [Loss: 1.793066e+01] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|7.28s  [Loss: 1.496643e+00]                                 \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "loss_values = train(\n",
    "    model=model,\n",
    "    data_set=train_data,\n",
    "    batch_size=20,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model(\n",
    "    test_data[:,:-1].float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = torch.argmax(predicts,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 2, 1, 0, 1, 2, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:,-1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9722)\n"
     ]
    }
   ],
   "source": [
    "# 打印准确率\n",
    "print(torch.sum(predicts == test_data[:,-1].int()) / test_data.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 支持向量机"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class SVMLinear(nn.Module):\n",
    "    def __init__(self,feature_num) -> None:\n",
    "        super(SVMLinear,self).__init__()\n",
    "        self.feature_num = feature_num\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_num) # 特征批量归一化，学习归一化参数\n",
    "        self.linear = nn.Linear(feature_num,1)\n",
    "    \n",
    "    def forward(self, x, signed = True):\n",
    "        B,d = x.shape\n",
    "        assert B > 0 and d == self.feature_num\n",
    "        normed = self.batch_norm(x)\n",
    "        outputs = self.linear(normed)\n",
    "        if signed:\n",
    "            return torch.sign(outputs)\n",
    "        else:\n",
    "            return outputs\n",
    "\n",
    "# 合页损失函数\n",
    "class HingeLoss(nn.Module):\n",
    "    def __init__(self,lamb) -> None:\n",
    "        super(HingeLoss,self).__init__()\n",
    "        self.lamb = lamb\n",
    "\n",
    "    def forward(self,res_pre_linear_values,res_rel,parameters):\n",
    "        return torch.sum(torch.relu(1 - res_rel*res_pre_linear_values)) + self.lamb*torch.norm(parameters)**2\n",
    "    \n",
    "def train_svm(model, data_set, batch_size, lamb=1, epoch = 1000, learning_rate = 1e-3):\n",
    "    N,_ = data_set.shape\n",
    "    criterion = HingeLoss(lamb)\n",
    "    optim = torch.optim.SGD(model.parameters(),learning_rate,momentum=0) # 动量设置为0\n",
    "    \n",
    "    start = time.time()\n",
    "    loss_values = torch.zeros(epoch)\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        index = torch.randint(0,N,[batch_size]) # 随机选取batch条数据\n",
    "        data_i = data_set[index,:]\n",
    "        x_i = data_i[:,:-1].to(torch.float32)\n",
    "        y_i = data_i[:,-1:].to(torch.int32)\n",
    "        outputs = model(x_i,signed=False)\n",
    "        loss = criterion(outputs,y_i,model.linear.weight)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        model.eval()\n",
    "        loss_values[i] = loss.item()\n",
    "\n",
    "        print('\\r%5d/{}|{}{}|{:.2f}s  [Loss: %e]'.format(\n",
    "            epoch,\n",
    "            \"#\"*int((i+1)/epoch*50),\n",
    "            \" \"*(50-int((i+1)/epoch*50)),\n",
    "            time.time() - start) %\n",
    "            (i+1,\n",
    "            loss_values[i]), end = ' ', flush=True)\n",
    "    print(\"\\nTraining has been completed.\")\n",
    "    return loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1 = SVMLinear(\n",
    "    feature_num=train_data.shape[1]-1\n",
    ")\n",
    "svm2 = SVMLinear(\n",
    "    feature_num=train_data.shape[1]-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_svm1 = copy.deepcopy(train_data)\n",
    "train_data_svm2 = copy.deepcopy(train_data)\n",
    "train_data_svm1[train_data_svm1[:,-1].int() > 0,-1] = -1\n",
    "train_data_svm1[train_data_svm1[:,-1].int() == 0,-1] = 1\n",
    "train_data_svm2 = train_data_svm2[train_data_svm2[:,-1].int() > 0,:]\n",
    "train_data_svm2[train_data_svm2[:,-1].int() == 2,-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([106, 14])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_svm1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([76, 14])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_svm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1., -1.,\n",
       "         1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,\n",
       "         1.,  1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.,\n",
       "        -1.,  1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1.,  1.,\n",
       "        -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "        -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,\n",
       "        -1., -1., -1.,  1., -1., -1., -1., -1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_svm1[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,\n",
       "         1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,\n",
       "         1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n",
       "         1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_svm2[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  166/2000|####                                              |0.48s  [Loss: 1.122805e+00] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|4.70s  [Loss: 2.529774e-01]                   \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "loss_values = train_svm(\n",
    "    model=svm1,\n",
    "    data_set=train_data_svm1,\n",
    "    batch_size=20,\n",
    "    lamb=0.1,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|4.82s  [Loss: 2.434435e-01]                 \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "loss_values = train_svm(\n",
    "    model=svm2,\n",
    "    data_set=train_data_svm2,\n",
    "    batch_size=20,\n",
    "    lamb=0.1,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_svm1 = svm1(\n",
    "    test_data[:,:-1].to(torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_svm2 = svm2(\n",
    "    test_data[pre_svm1[:,0] < 0,:-1].to(torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = pre_svm1[:,0]\n",
    "k = 0\n",
    "for i in range(predicts.shape[0]):\n",
    "    if predicts[i] > 0: predicts[i] = 0\n",
    "    elif predicts[i] < 0 and pre_svm2[k,0] > 0:\n",
    "        predicts[i] = 1\n",
    "        k += 1\n",
    "    else:\n",
    "        predicts[i] = 2\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 0, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 2, 2, 0, 2, 2, 2, 2, 1, 0, 1, 2, 0, 1, 0, 2],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:,-1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9444)\n"
     ]
    }
   ],
   "source": [
    "# 打印准确率\n",
    "print(torch.sum(predicts == test_data[:,-1].int()) / test_data.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 非线性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 观察数据分布\n",
    "train_data_nonlinear = copy.deepcopy(train_data)\n",
    "max = torch.max(train_data_nonlinear[:,:-1],dim=0).values\n",
    "min = torch.min(train_data_nonlinear[:,:-1],dim=0).values\n",
    "train_data_nonlinear[:,:-1] = (train_data_nonlinear[:,:-1] - min) / (max - min) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k1 = 1\n",
    "k2 = 2\n",
    "for i in range(train_data_nonlinear.shape[0]):\n",
    "    if train_data_nonlinear[i,-1].int() == 0:\n",
    "        plt.scatter(train_data_nonlinear[i,k1],train_data_nonlinear[i,k2],color='r')\n",
    "    else:\n",
    "        plt.scatter(train_data_nonlinear[i,k1],train_data_nonlinear[i,k2],color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k1 = 1\n",
    "k2 = 3\n",
    "for i in range(train_data_nonlinear.shape[0]):\n",
    "    if train_data_nonlinear[i,-1].int() == 0:\n",
    "        plt.scatter(train_data_nonlinear[i,k1],train_data_nonlinear[i,k2],color='r')\n",
    "    else:\n",
    "        plt.scatter(train_data_nonlinear[i,k1],train_data_nonlinear[i,k2],color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高斯核非线性SVM\n",
    "class SVMNonLinear(nn.Module):\n",
    "    def __init__(self,feature_num,kernel_data) -> None:\n",
    "        super(SVMNonLinear,self).__init__()\n",
    "        self.feature_num = feature_num\n",
    "        self.kernel_features = kernel_data[:,:-1].to(torch.float32)\n",
    "        self.kernel_labels = kernel_data[:,-1].to(torch.int32)\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_num)\n",
    "        self.linear = nn.Linear(feature_num+kernel_data.shape[0],1)\n",
    "        self.kernel_params = nn.Parameter(torch.rand(1)+5,requires_grad=True) # 核函数标准差\n",
    "    \n",
    "    def forward(self, x, signed = True):\n",
    "        B,d = x.shape\n",
    "        assert B > 0 and d == self.feature_num\n",
    "        # 归一化特征\n",
    "        normed_data = self.batch_norm(x)\n",
    "        normed_kernel_data = self.batch_norm(self.kernel_features)\n",
    "        kernel_features = torch.exp(-torch.mm(normed_data,normed_kernel_data.T) / self.kernel_params**2) * self.kernel_labels\n",
    "        outputs = self.linear(torch.cat([normed_data,kernel_features],dim=1)) # 核方法特征和原特征结合\n",
    "        if signed:\n",
    "            return torch.sign(outputs)\n",
    "        else:\n",
    "            return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_data_size = 20\n",
    "kernel_data_svm1 = copy.deepcopy(train_data)[:kernel_data_size]\n",
    "kernel_data_svm2 = copy.deepcopy(train_data)\n",
    "kernel_data_svm1[kernel_data_svm1[:,-1].int() > 0,-1] = -1\n",
    "kernel_data_svm1[kernel_data_svm1[:,-1].int() == 0,-1] = 1\n",
    "kernel_data_svm2 = kernel_data_svm2[kernel_data_svm2[:,-1].int() > 0,:][:kernel_data_size]\n",
    "kernel_data_svm2[kernel_data_svm2[:,-1].int() == 2,-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 14])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_data_svm1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 14])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_data_svm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1., -1.,\n",
       "         1., -1., -1., -1.,  1., -1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_data_svm1[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        -1.,  1., -1., -1.,  1.,  1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_data_svm2[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1 = SVMNonLinear(\n",
    "    feature_num=train_data.shape[1]-1,\n",
    "    kernel_data=kernel_data_svm1\n",
    ")\n",
    "svm2 = SVMNonLinear(\n",
    "    feature_num=train_data.shape[1]-1,\n",
    "    kernel_data=kernel_data_svm2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_svm1 = copy.deepcopy(train_data)\n",
    "train_data_svm2 = copy.deepcopy(train_data)\n",
    "train_data_svm1[train_data_svm1[:,-1].int() > 0,-1] = -1\n",
    "train_data_svm1[train_data_svm1[:,-1].int() == 0,-1] = 1\n",
    "train_data_svm2 = train_data_svm2[train_data_svm2[:,-1].int() > 0,:]\n",
    "train_data_svm2[train_data_svm2[:,-1].int() == 2,-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|6.18s  [Loss: 2.596327e-01]                         \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "loss_values = train_svm(\n",
    "    model=svm1,\n",
    "    data_set=train_data_svm1,\n",
    "    batch_size=20,\n",
    "    lamb=0.1,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|6.72s  [Loss: 2.472040e-01]                                  \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "loss_values = train_svm(\n",
    "    model=svm2,\n",
    "    data_set=train_data_svm2,\n",
    "    batch_size=20,\n",
    "    lamb=0.1,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_svm1 = svm1(\n",
    "    test_data[:,:-1].to(torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_svm2 = svm2(\n",
    "    test_data[pre_svm1[:,0] < 0,:-1].to(torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = pre_svm1[:,0]\n",
    "k = 0\n",
    "for i in range(predicts.shape[0]):\n",
    "    if predicts[i] > 0: predicts[i] = 0\n",
    "    elif predicts[i] < 0 and pre_svm2[k,0] > 0:\n",
    "        predicts[i] = 1\n",
    "        k += 1\n",
    "    else:\n",
    "        predicts[i] = 2\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 0, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 2, 1, 0, 1, 2, 0, 1, 0, 2],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:,-1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9583)\n"
     ]
    }
   ],
   "source": [
    "# 打印准确率\n",
    "print(torch.sum(predicts == test_data[:,-1].int()) / test_data.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层非线性感知机（神经网络）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,feature_num,class_num,hidden_dim=20,layer_num=2) -> None:\n",
    "        super(MLP,self).__init__()\n",
    "        self.feature_num = feature_num\n",
    "        self.class_num = class_num\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_num = layer_num\n",
    "        self.model = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [(\"input_layer\",\n",
    "                    nn.Sequential(\n",
    "                        nn.BatchNorm1d(feature_num),\n",
    "                        nn.Linear(feature_num,hidden_dim),\n",
    "                        nn.Tanh()\n",
    "                    ))] + \n",
    "                [(\"hidden_layer_\"+str(i+1),\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(hidden_dim,hidden_dim),\n",
    "                        nn.Tanh()\n",
    "                    )) for i in range(layer_num-1)] + \n",
    "                [(\"output_layer\",\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(hidden_dim,class_num),\n",
    "                        nn.Softmax(dim=1)\n",
    "                    ))]\n",
    "            )\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(\n",
    "    feature_num=train_data.shape[1]-1,\n",
    "    class_num=3,\n",
    "    hidden_dim=30,\n",
    "    layer_num=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|5.84s  [Loss: 1.520115e+00]                             \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "loss_values = train(\n",
    "    model=mlp,\n",
    "    data_set=train_data,\n",
    "    batch_size=20,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = mlp(\n",
    "    test_data[:,:-1].float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = torch.argmax(predicts,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 2, 1, 0, 1, 2, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:,-1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9722)\n"
     ]
    }
   ],
   "source": [
    "# 打印准确率\n",
    "print(torch.sum(predicts == test_data[:,-1].int()) / test_data.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
