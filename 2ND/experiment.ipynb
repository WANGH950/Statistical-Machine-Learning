{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计机器学习第二次作业\n",
    "### 葡萄酒品种分类——基于Pytorch\n",
    "王恒 计算数学 220220934161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2d0046c7e30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "import time\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "data =  datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = torch.tensor(data.data)\n",
    "data_labels = torch.tensor(data.target)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([178, 13])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([178, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = torch.cat([data_features,data_labels],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = data_set.shape[0]\n",
    "alpha = 0.6\n",
    "train_len = int(length*alpha)\n",
    "test_len = length - train_len\n",
    "train_data, test_data = torch.utils.data.random_split(data_set,[train_len,test_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_data = torch.tensor([item.numpy() for item in train_data])\n",
    "test_data = torch.tensor([item.numpy() for item in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([106, 14])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([72, 14])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class NaiveBayes(nn.Module):\n",
    "    def __init__(self, n, full_labels, S, lamb) -> None:\n",
    "        super(NaiveBayes,self).__init__()\n",
    "        # 归一化参数\n",
    "        self.max = None\n",
    "        self.min = None\n",
    "        self.n = n # 特征数量\n",
    "        self.full_labels = full_labels # 所有标签\n",
    "        self.K = len(full_labels) # 标签数量\n",
    "        self.lamb = lamb # 贝叶斯估计参数lambda\n",
    "        self.S = S # 每个特征分划区间数，这里默认都为S\n",
    "        self.cond_prob = torch.zeros([self.K,self.n,S]) # 条件概率\n",
    "        self.pre_prob = torch.zeros([self.K]) # 先验概率\n",
    "\n",
    "    def forward(self, features):\n",
    "        B,n = features.shape\n",
    "        assert n == self.n\n",
    "        post_prob = torch.ones([B,1])*self.pre_prob\n",
    "        # 归一化\n",
    "        features = (features - self.min) / (self.max - self.min) * 2 - 1\n",
    "        delta_x = 2 / (self.S - 2)\n",
    "        for i in range(B):\n",
    "            for j in range(self.K):\n",
    "                for k in range(n):\n",
    "                    # (-\\infty,-1)和(1,\\infty)的概率\n",
    "                    if features[i,k] < -1: post_prob[i,j] *= self.cond_prob[j,k,0]\n",
    "                    elif features[i,k] >= 1: post_prob[i,j] *= self.cond_prob[j,k,-1]\n",
    "                    else:\n",
    "                        for h in range(self.S-2):\n",
    "                            l = -1 + h * delta_x\n",
    "                            r = l + delta_x\n",
    "                            if features[i,k] >= l and features[i,k] < r:\n",
    "                                post_prob[i,j] *= self.cond_prob[j,k,h+1]\n",
    "                                break\n",
    "        return self.full_labels[torch.argmax(post_prob,dim=1)]\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        # 计算先验概率\n",
    "        N,_ = train_data.shape\n",
    "        self.max = torch.max(train_data[:,:-1],dim=0).values\n",
    "        self.min = torch.min(train_data[:,:-1],dim=0).values\n",
    "        train_data[:,:-1] = (train_data[:,:-1] - self.min) / (self.max - self.min) * 2 - 1\n",
    "        features = train_data[:,:-1] # 特征\n",
    "        labels = train_data[:,-1:].int() # 标签\n",
    "        delta_x = 2 / (self.S - 2)\n",
    "        for i in range(self.K):\n",
    "            labels_i = labels == self.full_labels[i]\n",
    "            self.pre_prob[i] = (labels_i.sum() + self.lamb) / (N + self.K*self.lamb)\n",
    "            for j in range(self.n):\n",
    "                self.cond_prob[i,j,0] = 1 / self.S\n",
    "                for k in range(self.S-1):\n",
    "                    l = -1 + k * delta_x\n",
    "                    r = l + delta_x\n",
    "                    features_ij = features[labels_i[:,0],j]\n",
    "                    features_ijk = features_ij[(features_ij>=l)*(features_ij<r)]\n",
    "                    self.cond_prob[i,j,k+1] = (features_ijk.shape[0] + self.lamb) / (labels_i.sum() + self.S*self.lamb)\n",
    "        return self.pre_prob, self.cond_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型实例化\n",
    "naive_bayse = NaiveBayes(\n",
    "    n=train_data.shape[1]-1,\n",
    "    full_labels=torch.tensor([0,1,2]),\n",
    "    S=10,\n",
    "    lamb=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "_,_ = naive_bayse.fit(\n",
    "    train_data = copy.deepcopy(train_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "predicts = naive_bayse(\n",
    "    copy.deepcopy(test_data[:,:-1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 0, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 1, 2, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印预测值\n",
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印真实值\n",
    "test_data[:,-1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9583)\n"
     ]
    }
   ],
   "source": [
    "# 打印准确率\n",
    "print(torch.sum(predicts == test_data[:,-1].int()) / test_data.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义模型（ID3算法）\n",
    "# class Node():\n",
    "#     def __init__(self, father = None, childrens = [], mark = None) -> None:\n",
    "#         super(Node,self).__init__()\n",
    "#         self.father = father\n",
    "#         self.childrens = childrens\n",
    "#         self.mark = mark\n",
    "#         self.split = []\n",
    "    \n",
    "#     def is_leaf(self):\n",
    "#         if self.mark is None:\n",
    "#             return False\n",
    "#         else:\n",
    "#             return True\n",
    "\n",
    "# class DecisionTree(nn.Module):\n",
    "#     def __init__(self, full_features, full_labels, S, esplison = 0.001) -> None:\n",
    "#         super(DecisionTree,self).__init__()\n",
    "#         self.esplison = esplison\n",
    "#         self.S = S # 特征划分数\n",
    "#         self.full_features = full_features\n",
    "#         self.feature_num = len(full_features)\n",
    "#         self.full_labels = full_labels\n",
    "#         self.K = len(full_labels)\n",
    "#         # 归一化参数\n",
    "#         self.min = None\n",
    "#         self.max = None\n",
    "#         self.Tree = Node()\n",
    "\n",
    "#     def create_tree(self,D,A,node = None,root = None):\n",
    "#         if node is None: \n",
    "#             node = self.Tree\n",
    "#             root = self.Tree\n",
    "#             # 归一化\n",
    "#             self.max = torch.max(D[:,:-1],dim=0).values\n",
    "#             self.min = torch.min(D[:,:-1],dim=0).values\n",
    "#             D[:,:-1] = (D[:,:-1] - self.min) / (self.max - self.min) * 2 - 1\n",
    "#         features = D[:,:-1]\n",
    "#         labels = D[:,-1:]\n",
    "#         # 只有一种标签时候直接返回\n",
    "#         if torch.unique(labels).shape[0] == 1:\n",
    "#             node.mark = D[0,-1]\n",
    "#             return root\n",
    "#         # 标签数量为空时直接返回\n",
    "#         elif len(A) == 0:\n",
    "#             count = torch.bincount(labels)\n",
    "#             mark = torch.argmax(count)\n",
    "#             node.mark = mark\n",
    "#             return root\n",
    "#         else:\n",
    "#             # 计算各特征的信息增益，选择最大信息增益特征\n",
    "#             g = self.information_gain(D,A[0])\n",
    "#             Ag = 0\n",
    "#             for i in range(len(A) - 1):\n",
    "#                 gi = self.information_gain(D,A[i+1])\n",
    "#                 if gi > g:\n",
    "#                     g = gi\n",
    "#                     Ag = i+1\n",
    "#             # 达到精度返回\n",
    "#             if g < self.esplison:\n",
    "#                 count = torch.bincount(labels)\n",
    "#                 mark = torch.argmax(count)\n",
    "#                 node.mark = mark\n",
    "#                 return root\n",
    "#             # 未达到精度继续递归生成子节点\n",
    "#             else:\n",
    "#                 l = None\n",
    "#                 r = -1\n",
    "#                 delta_x = 2 / (self.S - 2)\n",
    "#                 feature_i = features[:,Ag]\n",
    "#                 Ai = copy.deepcopy(A)\n",
    "#                 Ai[Ag] = False\n",
    "#                 for i in range(self.S):\n",
    "#                     if i == self.S - 1: r = None\n",
    "#                     if l is None:\n",
    "#                         index = feature_i < r\n",
    "#                         # 当前数据不空\n",
    "#                         if index.sum() > 0:\n",
    "#                             node.split.append(lambda x: x < r) # 用于判别并分划当前特征\n",
    "#                             Di = D[index,:] # Di一定非空\n",
    "#                             assert Di.shape[0] > 0\n",
    "#                             nodei = Node(father=node)\n",
    "#                             # 递归处理子节点\n",
    "#                             self.create_tree(Di,Ai,nodei,root)\n",
    "#                             node.childrens.append(nodei)\n",
    "#                             l = r\n",
    "#                             r = r + delta_x\n",
    "#                     elif r is None:\n",
    "#                         index = feature_i >= l\n",
    "#                         # 当前数据不空\n",
    "#                         if index.sum() > 0:\n",
    "#                             node.split.append(lambda x: x < r) # 用于判别并分划当前特征\n",
    "#                             Di = D[index,:] # Di一定非空\n",
    "#                             assert Di.shape[0] > 0\n",
    "#                             nodei = Node(father=node)\n",
    "#                             # 递归处理子节点\n",
    "#                             self.create_tree(Di,Ai,nodei,root)\n",
    "#                             node.childrens.append(nodei)\n",
    "#                             l = r\n",
    "#                             r = r + delta_x\n",
    "                        \n",
    "                            \n",
    "                \n",
    "\n",
    "#     # 计算经验熵\n",
    "#     def empirical_entropy(self,D):\n",
    "#         labels = data_set[:,-1:]\n",
    "#         HD = 0\n",
    "#         for j in range(self.K):\n",
    "#             labels_j = labels == self.full_labels[j]\n",
    "#             HD -= labels_j.sum() / D * torch.log2(labels_j.sum() / D)\n",
    "#         return HD\n",
    "\n",
    "#     # 计算A对于数据集D的经验条件熵\n",
    "#     def empirical_cond_entropy(self,D,A):\n",
    "#         D_ = D.shape[0]\n",
    "#         index = self.full_features == A\n",
    "#         features = D[:,:-1]\n",
    "#         labels = D[:,-1:]\n",
    "#         DA = features[:,index]\n",
    "#         DAi = DA[DA < -1,None]\n",
    "#         Li = labels[DA < -1,:]\n",
    "#         HDA = len(DAi) / D_ * self.empirical_entropy(torch.cat([DAi,Li],dim=1))\n",
    "#         DAi = DA[DA >= 1,None]\n",
    "#         Li = labels[DA >= 1,:]\n",
    "#         HDA += len(DAi) / D_ * self.empirical_entropy(torch.cat([DAi,Li],dim=1))\n",
    "#         delta_x = 2 / (self.S - 2)\n",
    "#         for i in range(self.S - 2):\n",
    "#             l = -1 + i * delta_x\n",
    "#             r = l + delta_x\n",
    "#             index_i = (DA >= l) * (DA < r)\n",
    "#             DAi = DA[index_i,None]\n",
    "#             Li = labels[index_i,:]\n",
    "#             HDA += len(DAi) / D_ * self.empirical_entropy(torch.cat([DAi,Li],dim=1))\n",
    "#         return HDA\n",
    "\n",
    "#     # 计算信息增益\n",
    "#     def information_gain(self,data_set,feature):\n",
    "#         if self.min is None or self.max is None:\n",
    "#             self.max = torch.max(train_data[:,:-1],dim=0).values\n",
    "#             self.min = torch.min(train_data[:,:-1],dim=0).values\n",
    "#         # 特征归一化到[-1,1]\n",
    "#         train_data[:,:-1] = (train_data[:,:-1] - self.min) / (self.max - self.min) * 2 - 1\n",
    "\n",
    "#         index = self.full_features == feature\n",
    "#         D,_ = data_set\n",
    "#         assert torch.sum(index) == 1 and D > 1\n",
    "#         # 计算经验熵\n",
    "#         HD = self.empirical_entropy(data_set)\n",
    "#         # 计算feature对于数据集data_set的经验条件熵\n",
    "#         HDA = self.empirical_cond_entropy(data_set,feature)\n",
    "#         return HD - HDA\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic 回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class Logistic(nn.Module):\n",
    "    def __init__(self,feature_num,class_num) -> None:\n",
    "        super(Logistic,self).__init__()\n",
    "        self.feature_num = feature_num\n",
    "        self.class_num = class_num\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.BatchNorm1d(feature_num), # 批量归一化\n",
    "            nn.Linear(feature_num,class_num-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,d = x.shape\n",
    "        assert d == self.feature_num and B > 0\n",
    "        y = torch.cat([torch.exp(self.linear(x)),torch.ones([B,1])],dim=1)\n",
    "        y = y / torch.sum(y,dim=1,keepdim=True)\n",
    "        return y\n",
    "    \n",
    "# 负对数似然损失函数\n",
    "class NLLLoss(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self,y_pre,y_rel):\n",
    "        assert y_pre.shape == y_rel.shape\n",
    "        loss = -torch.log(y_pre)*y_rel\n",
    "        return torch.sum(loss)\n",
    "\n",
    "# 定义模型训练函数\n",
    "def train(model, data_set, batch_size, epoch = 1000, learning_rate = 1e-3):\n",
    "    N,_ = data_set.shape\n",
    "    criterion = NLLLoss()\n",
    "    optim = torch.optim.SGD(model.parameters(),learning_rate,momentum=0) # 动量设置为0\n",
    "    \n",
    "    start = time.time()\n",
    "    loss_values = torch.zeros(epoch)\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        index = torch.randint(0,N,[batch_size]) # 随机选取batch条数据\n",
    "        data_i = data_set[index,:]\n",
    "        x_i = data_i[:,:-1].to(torch.float32)\n",
    "        y_i = nn.functional.one_hot(data_i[:,-1].to(torch.int64),num_classes=model.class_num)\n",
    "        outputs = model(x_i)\n",
    "        loss = criterion(outputs,y_i)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        model.eval()\n",
    "        loss_values[i] = loss.item()\n",
    "\n",
    "        print('\\r%5d/{}|{}{}|{:.2f}s  [Loss: %e]'.format(\n",
    "            epoch,\n",
    "            \"#\"*int((i+1)/epoch*50),\n",
    "            \" \"*(50-int((i+1)/epoch*50)),\n",
    "            time.time() - start) %\n",
    "            (i+1,\n",
    "            loss_values[i]), end = ' ', flush=True)\n",
    "    print(\"\\nTraining has been completed.\")\n",
    "    return loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型实例化\n",
    "model = Logistic(\n",
    "    feature_num=train_data.shape[1]-1,\n",
    "    class_num=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|7.46s  [Loss: 1.169330e+00]                             \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "loss_values = train(\n",
    "    model=model,\n",
    "    data_set=train_data,\n",
    "    batch_size=20,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "predicts = model(\n",
    "    test_data[:,:-1].float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到预测结果的原格式\n",
    "predicts = torch.argmax(predicts,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 2, 1, 0, 1, 2, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印预测值\n",
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印真实值\n",
    "test_data[:,-1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9722)\n"
     ]
    }
   ],
   "source": [
    "# 打印准确率\n",
    "print(torch.sum(predicts == test_data[:,-1].int()) / test_data.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 支持向量机"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class SVMLinear(nn.Module):\n",
    "    def __init__(self,feature_num) -> None:\n",
    "        super(SVMLinear,self).__init__()\n",
    "        self.feature_num = feature_num\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_num) # 特征批量归一化，学习归一化参数\n",
    "        self.linear = nn.Linear(feature_num,1)\n",
    "    \n",
    "    def forward(self, x, signed = True):\n",
    "        B,d = x.shape\n",
    "        assert B > 0 and d == self.feature_num\n",
    "        normed = self.batch_norm(x)\n",
    "        outputs = self.linear(normed)\n",
    "        if signed:\n",
    "            return torch.sign(outputs)\n",
    "        else:\n",
    "            return outputs\n",
    "\n",
    "# 合页损失函数\n",
    "class HingeLoss(nn.Module):\n",
    "    def __init__(self,lamb) -> None:\n",
    "        super(HingeLoss,self).__init__()\n",
    "        self.lamb = lamb\n",
    "\n",
    "    def forward(self,res_pre_linear_values,res_rel,parameters):\n",
    "        return torch.sum(torch.relu(1 - res_rel*res_pre_linear_values)) + self.lamb*torch.norm(parameters)**2\n",
    "\n",
    "# 定义训练函数\n",
    "def train_svm(model, data_set, batch_size, lamb=1, epoch = 1000, learning_rate = 1e-3):\n",
    "    N,_ = data_set.shape\n",
    "    criterion = HingeLoss(lamb)\n",
    "    optim = torch.optim.SGD(model.parameters(),learning_rate,momentum=0) # 动量设置为0\n",
    "    \n",
    "    start = time.time()\n",
    "    loss_values = torch.zeros(epoch)\n",
    "    for i in range(epoch):\n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        index = torch.randint(0,N,[batch_size]) # 随机选取batch条数据\n",
    "        data_i = data_set[index,:]\n",
    "        x_i = data_i[:,:-1].to(torch.float32)\n",
    "        y_i = data_i[:,-1:].to(torch.int32)\n",
    "        outputs = model(x_i,signed=False)\n",
    "        loss = criterion(outputs,y_i,model.linear.weight)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        model.eval()\n",
    "        loss_values[i] = loss.item()\n",
    "\n",
    "        print('\\r%5d/{}|{}{}|{:.2f}s  [Loss: %e]'.format(\n",
    "            epoch,\n",
    "            \"#\"*int((i+1)/epoch*50),\n",
    "            \" \"*(50-int((i+1)/epoch*50)),\n",
    "            time.time() - start) %\n",
    "            (i+1,\n",
    "            loss_values[i]), end = ' ', flush=True)\n",
    "    print(\"\\nTraining has been completed.\")\n",
    "    return loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将第一类与其他类分开\n",
    "svm1 = SVMLinear(\n",
    "    feature_num=train_data.shape[1]-1\n",
    ")\n",
    "# 将第二类和第三类分开\n",
    "svm2 = SVMLinear(\n",
    "    feature_num=train_data.shape[1]-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_svm1 = copy.deepcopy(train_data)\n",
    "train_data_svm2 = copy.deepcopy(train_data)\n",
    "train_data_svm1[train_data_svm1[:,-1].int() > 0,-1] = -1\n",
    "train_data_svm1[train_data_svm1[:,-1].int() == 0,-1] = 1\n",
    "train_data_svm2 = train_data_svm2[train_data_svm2[:,-1].int() > 0,:]\n",
    "train_data_svm2[train_data_svm2[:,-1].int() == 2,-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([106, 14])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_svm1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([76, 14])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_svm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1., -1.,\n",
       "         1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,\n",
       "         1.,  1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.,\n",
       "        -1.,  1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1.,  1.,\n",
       "        -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "        -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,\n",
       "        -1., -1., -1.,  1., -1., -1., -1., -1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_svm1[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,\n",
       "         1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,\n",
       "         1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n",
       "         1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_svm2[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|5.13s  [Loss: 2.021314e+00]                        \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "# 训练模型1\n",
    "loss_values = train_svm(\n",
    "    model=svm1,\n",
    "    data_set=train_data_svm1,\n",
    "    batch_size=20,\n",
    "    lamb=0.1,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|5.18s  [Loss: 2.357707e-01]                         \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "# 训练模型2\n",
    "loss_values = train_svm(\n",
    "    model=svm2,\n",
    "    data_set=train_data_svm2,\n",
    "    batch_size=20,\n",
    "    lamb=0.1,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型1预测\n",
    "pre_svm1 = svm1(\n",
    "    test_data[:,:-1].to(torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于模型1的模型2预测\n",
    "pre_svm2 = svm2(\n",
    "    test_data[pre_svm1[:,0] < 0,:-1].to(torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换预测结果\n",
    "predicts = pre_svm1[:,0]\n",
    "k = 0\n",
    "for i in range(predicts.shape[0]):\n",
    "    if predicts[i] > 0: predicts[i] = 0\n",
    "    elif predicts[i] < 0 and pre_svm2[k,0] > 0:\n",
    "        predicts[i] = 1\n",
    "        k += 1\n",
    "    else:\n",
    "        predicts[i] = 2\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 0, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 2, 2, 0, 2, 2, 2, 2, 1, 0, 1, 2, 0, 1, 0, 2],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印预测值\n",
    "predicts.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印真实值\n",
    "test_data[:,-1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9444)\n"
     ]
    }
   ],
   "source": [
    "# 打印准确率\n",
    "print(torch.sum(predicts == test_data[:,-1].int()) / test_data.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 非线性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 观察数据分布\n",
    "train_data_nonlinear = copy.deepcopy(train_data)\n",
    "max = torch.max(train_data_nonlinear[:,:-1],dim=0).values\n",
    "min = torch.min(train_data_nonlinear[:,:-1],dim=0).values\n",
    "train_data_nonlinear[:,:-1] = (train_data_nonlinear[:,:-1] - min) / (max - min) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k1 = 1\n",
    "k2 = 2\n",
    "for i in range(train_data_nonlinear.shape[0]):\n",
    "    if train_data_nonlinear[i,-1].int() == 0:\n",
    "        plt.scatter(train_data_nonlinear[i,k1],train_data_nonlinear[i,k2],color='r')\n",
    "    else:\n",
    "        plt.scatter(train_data_nonlinear[i,k1],train_data_nonlinear[i,k2],color='b')\n",
    "plt.xlabel('$x_'+str(k1+1)+'$')\n",
    "plt.ylabel('$x_'+str(k2+1)+'$')\n",
    "plt.savefig('./figure/svm1.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k1 = 1\n",
    "k2 = 3\n",
    "for i in range(train_data_nonlinear.shape[0]):\n",
    "    if train_data_nonlinear[i,-1].int() == 0:\n",
    "        plt.scatter(train_data_nonlinear[i,k1],train_data_nonlinear[i,k2],color='r')\n",
    "    else:\n",
    "        plt.scatter(train_data_nonlinear[i,k1],train_data_nonlinear[i,k2],color='b')\n",
    "plt.xlabel('$x_'+str(k1+1)+'$')\n",
    "plt.ylabel('$x_'+str(k2+1)+'$')\n",
    "plt.savefig('./figure/svm2.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 高斯核非线性SVM\n",
    "class SVMNonLinear(nn.Module):\n",
    "    def __init__(self,feature_num,kernel_data) -> None:\n",
    "        super(SVMNonLinear,self).__init__()\n",
    "        self.feature_num = feature_num\n",
    "        self.kernel_features = kernel_data[:,:-1].to(torch.float32)\n",
    "        self.kernel_labels = kernel_data[:,-1].to(torch.int32)\n",
    "        self.batch_norm = nn.BatchNorm1d(feature_num)\n",
    "        self.linear = nn.Linear(feature_num+kernel_data.shape[0],1)\n",
    "        self.kernel_params = nn.Parameter(torch.rand(1)+5,requires_grad=True) # 核函数标准差\n",
    "    \n",
    "    def forward(self, x, signed = True):\n",
    "        B,d = x.shape\n",
    "        assert B > 0 and d == self.feature_num\n",
    "        # 归一化特征\n",
    "        normed_data = self.batch_norm(x)\n",
    "        normed_kernel_data = self.batch_norm(self.kernel_features)\n",
    "        kernel_features = torch.exp(-torch.mm(normed_data,normed_kernel_data.T) / self.kernel_params**2) * self.kernel_labels\n",
    "        outputs = self.linear(torch.cat([normed_data,kernel_features],dim=1)) # 核方法特征和原特征结合\n",
    "        if signed:\n",
    "            return torch.sign(outputs)\n",
    "        else:\n",
    "            return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_data_size = 20\n",
    "kernel_data_svm1 = copy.deepcopy(train_data)[:kernel_data_size]\n",
    "kernel_data_svm2 = copy.deepcopy(train_data)\n",
    "kernel_data_svm1[kernel_data_svm1[:,-1].int() > 0,-1] = -1\n",
    "kernel_data_svm1[kernel_data_svm1[:,-1].int() == 0,-1] = 1\n",
    "kernel_data_svm2 = kernel_data_svm2[kernel_data_svm2[:,-1].int() > 0,:][:kernel_data_size]\n",
    "kernel_data_svm2[kernel_data_svm2[:,-1].int() == 2,-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 14])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_data_svm1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 14])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_data_svm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1., -1.,\n",
       "         1., -1., -1., -1.,  1., -1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_data_svm1[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        -1.,  1., -1., -1.,  1.,  1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_data_svm2[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1 = SVMNonLinear(\n",
    "    feature_num=train_data.shape[1]-1,\n",
    "    kernel_data=kernel_data_svm1\n",
    ")\n",
    "svm2 = SVMNonLinear(\n",
    "    feature_num=train_data.shape[1]-1,\n",
    "    kernel_data=kernel_data_svm2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_svm1 = copy.deepcopy(train_data)\n",
    "train_data_svm2 = copy.deepcopy(train_data)\n",
    "train_data_svm1[train_data_svm1[:,-1].int() > 0,-1] = -1\n",
    "train_data_svm1[train_data_svm1[:,-1].int() == 0,-1] = 1\n",
    "train_data_svm2 = train_data_svm2[train_data_svm2[:,-1].int() > 0,:]\n",
    "train_data_svm2[train_data_svm2[:,-1].int() == 2,-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|6.65s  [Loss: 2.499684e-01]                                          \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "loss_values = train_svm(\n",
    "    model=svm1,\n",
    "    data_set=train_data_svm1,\n",
    "    batch_size=20,\n",
    "    lamb=0.1,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000/2000|##################################################|6.98s  [Loss: 2.431201e-01]                                                 \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "loss_values = train_svm(\n",
    "    model=svm2,\n",
    "    data_set=train_data_svm2,\n",
    "    batch_size=20,\n",
    "    lamb=0.1,\n",
    "    epoch=2000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_svm1 = svm1(\n",
    "    test_data[:,:-1].to(torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_svm2 = svm2(\n",
    "    test_data[pre_svm1[:,0] < 0,:-1].to(torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = pre_svm1[:,0]\n",
    "k = 0\n",
    "for i in range(predicts.shape[0]):\n",
    "    if predicts[i] > 0: predicts[i] = 0\n",
    "    elif predicts[i] < 0 and pre_svm2[k,0] > 0:\n",
    "        predicts[i] = 1\n",
    "        k += 1\n",
    "    else:\n",
    "        predicts[i] = 2\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 0, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 2, 1, 0, 1, 2, 0, 1, 0, 2],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:,-1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9583)\n"
     ]
    }
   ],
   "source": [
    "# 打印准确率\n",
    "print(torch.sum(predicts == test_data[:,-1].int()) / test_data.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层非线性感知机（神经网络）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,feature_num,class_num,hidden_dim=20,layer_num=2) -> None:\n",
    "        super(MLP,self).__init__()\n",
    "        self.feature_num = feature_num\n",
    "        self.class_num = class_num\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_num = layer_num\n",
    "        self.model = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [(\"input_layer\",\n",
    "                    nn.Sequential(\n",
    "                        nn.BatchNorm1d(feature_num),\n",
    "                        nn.Linear(feature_num,hidden_dim),\n",
    "                        nn.SiLU()\n",
    "                    ))] + \n",
    "                [(\"hidden_layer_\"+str(i+1),\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(hidden_dim,hidden_dim),\n",
    "                        nn.SiLU()\n",
    "                    )) for i in range(layer_num-1)] + \n",
    "                [(\"output_layer\",\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(hidden_dim,class_num),\n",
    "                        nn.Softmax(dim=1)\n",
    "                    ))]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # 前向传播\n",
    "    def forward(self,x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "mlp = MLP(\n",
    "    feature_num=train_data.shape[1]-1,\n",
    "    class_num=3,\n",
    "    hidden_dim=30,\n",
    "    layer_num=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3000/3000|##################################################|13.01s  [Loss: 1.494318e-01]                                                  \n",
      "Training has been completed.\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "loss_values = train(\n",
    "    model=mlp,\n",
    "    data_set=train_data,\n",
    "    batch_size=20,\n",
    "    epoch=3000,\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = mlp(\n",
    "    test_data[:,:-1].float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = torch.argmax(predicts,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 2, 1, 0, 1, 2, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 1, 0, 0, 0, 0, 2,\n",
       "        0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 1, 0, 2],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:,-1].int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9722)\n"
     ]
    }
   ],
   "source": [
    "# 打印准确率\n",
    "print(torch.sum(predicts == test_data[:,-1].int()) / test_data.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
